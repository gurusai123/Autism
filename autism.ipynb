{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data sets//data_autism.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>result</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Spain</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Parent</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>?</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Russia</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Parent</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>702</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Russia</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>?</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>m</td>\n",
       "      <td>South Asian</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>704</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>no</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  \\\n",
       "0      1         1         1         1         1         0         0   \n",
       "1      2         1         1         0         1         0         0   \n",
       "2      3         1         1         0         1         1         0   \n",
       "3      4         1         1         0         1         0         0   \n",
       "4      5         1         0         0         0         0         0   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "699  700         0         1         0         1         1         0   \n",
       "700  701         1         0         0         0         0         0   \n",
       "701  702         1         0         1         1         1         0   \n",
       "702  703         1         0         0         1         1         0   \n",
       "703  704         1         0         1         1         1         0   \n",
       "\n",
       "     A7_Score  A8_Score  A9_Score  ...  result gender       ethnicity jundice  \\\n",
       "0           1         1         0  ...       6      f  White-European      no   \n",
       "1           0         1         0  ...       5      m          Latino      no   \n",
       "2           1         1         1  ...       8      m          Latino     yes   \n",
       "3           1         1         0  ...       6      f  White-European      no   \n",
       "4           0         1         0  ...       2      f               ?      no   \n",
       "..        ...       ...       ...  ...     ...    ...             ...     ...   \n",
       "699         1         1         1  ...       7      f  White-European      no   \n",
       "700         0         1         0  ...       3      m        Hispanic      no   \n",
       "701         1         1         0  ...       7      f               ?      no   \n",
       "702         1         0         1  ...       6      m     South Asian      no   \n",
       "703         1         1         1  ...       8      f  White-European      no   \n",
       "\n",
       "    austim  contry_of_res used_app_before     age_desc relation Class/ASD  \n",
       "0       no  United States              no  18 and more     Self        NO  \n",
       "1      yes         Brazil              no  18 and more     Self        NO  \n",
       "2      yes          Spain              no  18 and more   Parent       YES  \n",
       "3      yes  United States              no  18 and more     Self        NO  \n",
       "4       no          Egypt              no  18 and more        ?        NO  \n",
       "..     ...            ...             ...          ...      ...       ...  \n",
       "699     no         Russia              no  18 and more     Self       YES  \n",
       "700     no         Mexico              no  18 and more   Parent        NO  \n",
       "701     no         Russia              no  18 and more        ?       YES  \n",
       "702     no       Pakistan              no  18 and more     Self        NO  \n",
       "703     no         Cyprus              no  18 and more     Self       YES  \n",
       "\n",
       "[704 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['id','used_app_before','age_desc'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.721591</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.457386</td>\n",
       "      <td>0.495739</td>\n",
       "      <td>0.498580</td>\n",
       "      <td>0.284091</td>\n",
       "      <td>0.417614</td>\n",
       "      <td>0.649148</td>\n",
       "      <td>0.323864</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>4.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.448535</td>\n",
       "      <td>0.498152</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>0.500337</td>\n",
       "      <td>0.500353</td>\n",
       "      <td>0.451301</td>\n",
       "      <td>0.493516</td>\n",
       "      <td>0.477576</td>\n",
       "      <td>0.468281</td>\n",
       "      <td>0.494866</td>\n",
       "      <td>2.501493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1_Score    A2_Score    A3_Score    A4_Score    A5_Score    A6_Score  \\\n",
       "count  704.000000  704.000000  704.000000  704.000000  704.000000  704.000000   \n",
       "mean     0.721591    0.453125    0.457386    0.495739    0.498580    0.284091   \n",
       "std      0.448535    0.498152    0.498535    0.500337    0.500353    0.451301   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         A7_Score    A8_Score    A9_Score   A10_Score      result  \n",
       "count  704.000000  704.000000  704.000000  704.000000  704.000000  \n",
       "mean     0.417614    0.649148    0.323864    0.573864    4.875000  \n",
       "std      0.493516    0.477576    0.468281    0.494866    2.501493  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    3.000000  \n",
       "50%      0.000000    1.000000    0.000000    1.000000    4.000000  \n",
       "75%      1.000000    1.000000    1.000000    1.000000    7.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000   10.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score         0\n",
       "A2_Score         0\n",
       "A3_Score         0\n",
       "A4_Score         0\n",
       "A5_Score         0\n",
       "A6_Score         0\n",
       "A7_Score         0\n",
       "A8_Score         0\n",
       "A9_Score         0\n",
       "A10_Score        0\n",
       "age              0\n",
       "result           0\n",
       "gender           0\n",
       "ethnicity        0\n",
       "jundice          0\n",
       "austim           0\n",
       "contry_of_res    0\n",
       "relation         0\n",
       "Class/ASD        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ethnicity'] == '?'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['relation'] == '?'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "data = pd.DataFrame(imp.fit_transform(data),columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ethnicity'] == '?'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['relation'] == '?'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO', 'YES'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class/ASD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class/ASD'].replace(['NO', 'YES'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class/ASD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].replace(['f', 'm'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['jundice'].replace(['no', 'yes'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['austim'].replace(['no', 'yes'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['relation'].replace(['self', 'Parent'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>result</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>White-European</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Latino</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Parent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>White-European</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>White-European</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>White-European</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Self</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Parent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>White-European</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Self</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>South Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>White-European</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>Self</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score  \\\n",
       "0          1        1        1        1        0        0        1        1   \n",
       "1          1        1        0        1        0        0        0        1   \n",
       "2          1        1        0        1        1        0        1        1   \n",
       "3          1        1        0        1        0        0        1        1   \n",
       "4          1        0        0        0        0        0        0        1   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "699        0        1        0        1        1        0        1        1   \n",
       "700        1        0        0        0        0        0        0        1   \n",
       "701        1        0        1        1        1        0        1        1   \n",
       "702        1        0        0        1        1        0        1        0   \n",
       "703        1        0        1        1        1        0        1        1   \n",
       "\n",
       "    A9_Score A10_Score age result  gender       ethnicity  jundice  austim  \\\n",
       "0          0         0  26      6       0  White-European        0       0   \n",
       "1          0         1  24      5       1          Latino        0       1   \n",
       "2          1         1  27      8       1          Latino        1       1   \n",
       "3          0         1  35      6       0  White-European        0       1   \n",
       "4          0         0  40      2       0  White-European        0       0   \n",
       "..       ...       ...  ..    ...     ...             ...      ...     ...   \n",
       "699        1         1  25      7       0  White-European        0       0   \n",
       "700        0         1  34      3       1        Hispanic        0       0   \n",
       "701        0         1  24      7       0  White-European        0       0   \n",
       "702        1         1  35      6       1     South Asian        0       0   \n",
       "703        1         1  26      8       0  White-European        0       0   \n",
       "\n",
       "     contry_of_res relation  Class/ASD  \n",
       "0    United States     Self          0  \n",
       "1           Brazil     Self          0  \n",
       "2            Spain   Parent          1  \n",
       "3    United States     Self          0  \n",
       "4            Egypt     Self          0  \n",
       "..             ...      ...        ...  \n",
       "699         Russia     Self          1  \n",
       "700         Mexico   Parent          0  \n",
       "701         Russia     Self          1  \n",
       "702       Pakistan     Self          0  \n",
       "703         Cyprus     Self          1  \n",
       "\n",
       "[704 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot_e(e):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    sns.countplot(x='contry_of_res',data=data[data['ethnicity']==e],order=data[data['ethnicity']==e]['contry_of_res'].value_counts().index[:10],palette='viridis')\n",
    "    plt.title(f'Positive ASD of {e} Ethnicities country wise distribution')\n",
    "    plt.xlabel('Countries')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAGoCAYAAACwmRWfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3debxtZV0/8M9XwCkQRK4TqDjlUCnmdUpEHPKn5oCmojlAamRlamVmaYWZpuaYQ2ap4AzOaM4mIJoDKIM4oQhqIIKAgKkJPr8/1nO4+x72me49+551732/X6/zOmuvtfZaz17TXuuznvXsaq0FAAAAYMyutNYFAAAAAFiKAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYABs5arqhlV1SVXtsMg4l1TVTbZkudZCVT2kqr7XP+/tNmM6H66qgxYYtndVtaracYHhh1bVW5YzLkurqoOr6rhNfO+S+0Yf725V9Y3NnQ4Lq6q/qar/mPE89q+q70+8PrWq9l+laT+6qj428bpV1c1WY9p9etvFMRpgcwkwALawqjqjqn7aT1jPqao3VtXOmzq91tp3W2s7t9Yu69M/uqqeOG+cnVtrp29u2aepqhtX1S+r6jVThj24qk6sqouq6ryq+mRV7d2HHVpVv6iqi/vfN6vqVVV1vc0ozouTPLl/3i9PKU/ry3zHiX47VtUPq6rN9Wut3a+1dvhmlGOzTSyfSyb+LtzMaa55oFJVh1XV/837XCfNonzz941Fxvt0a+0WE2U8o6ruvdLpjN1arv/W2vNba09cesxVneevtdaOXmyc5S6T1tpbW2v3WY1ybeljNMC2RIABsDYe2FrbOclvJrlDkmevcXk2x+OSXJDkkVV1lbme/e7km5L8RZJdk9w4yWuS/HLivUe01nZJsnuShyS5bpITNiPEuFGSU5cY58Ik95t4ff9e/jE6ol/YzP3ttpaFWcUL3xfN+1y3XaXpspnUFroiywRgPAQYAGuotfY/ST6c5NeTpKquX1VHVdX5VfWtqvqDuXGr6o5VdXyvzXBOVb2097/8DmJVPS/J3ZK8qt/ZflUfp1XVzarqzlX1g8mq8P2xi5N795Wq6plV9e2q+lFVHVlVuy/xMR6XIYD5RZIHTvTfJ8l3WmufbIOLW2vvbq19d8py+EVr7dQkByY5N0PocQW9fM+uqjN7rYk3VdWuVXWVqrokyQ5JTqqqby9S3jf3Mk+W/03z5nP5HdKq2qGqXtxrkJye5HfmjXvjqjqm1yL5eJI9FppxL+vrq+rsqvqfqvrH2sTHEqrqFTU8LnNRVZ1QVXebGDZ1W0lybP9/Yd8+7tLHf3xVfa2qLqiqj1bVjSam1arqT6rqtCSnTfR7UlWd1t/z6qqqTfkc80wtX5/ni/u8vlNV95vof3RVPbeqPtPXwceqao8+bKO761W1ew01ns7q03pf73/5owdV9eYkN0zygV6GZ0yZzoLrse9nx1TVj/s2c8RCH7aq9q2qz1bVhX1dHjwx/TdV1bl9W392VV2pD7v8EaUFPuOCy2Pa8q3hEZ3PVNXLqur8JM+t4fjzGxPzuHYNtcbWTfkMZ1bV7Xv3Y3pZbt1fP3FiGU8+WnXVqnpLDceYC6vqi1V1naWW7ZR5X62GGj0XVNVXM4TBk8Mvr0mzkn1iyjI5tKY/ynT/qjq9r+d/Xs46qiWO0ctY/wdX1XG1wP4AsK0TYACsoaq6QYYaAHOPO7w9yfeTXD/Jw5I8v6ru1Ye9IskrWmvXSHLTJEfOn15r7VlJPp0Nj1E8ed7wzyX5SZJ7TvT+vSRv691PSXJAkrv3MlyQ5NWLlP9uSfZK8o5enslg4EtJbtkvAu5Ry3hMplfRf3+GE/xpDu5/90hykyQ7J3lVa+3nvUZLkty2tXbTRWbzviT7VdVuVbVbn9f7Fxn/D5I8IMntkqzPsF4mvS3JCRmCi+cmmdp2Rnd4kkuT3KxP7z5JNrVa/RczhES79zK8s6qu2octtK3s1//v1reP/66qA5L8TZKHJlmXYft5+7x5HZDkTkluPdHvARkuGG+b5BFJ/t8mfo5JVyhff32nJN/IsIxflOT1VRsFJr+X5PeTXDvJlZM8fYHpvznJ1ZP8Wh/3ZfNHaK09Nsl302tJtdZeNGU6i63H5yb5WJJrZtg3XjmtIFV1wwzh5SszLPd9kpzYB78yQ62lm2TYFx/XP99yLbQ8Flu+p/fx/yHD/vyYiek9KsknWmvnTpnXMUn2n5j+6b3Mc6+PmfKegzJ8vhskuVaSJyX5aR+2kn3k7zNs3zfNsP0ttu8te5/oryeXyfMWmOZDMhwTfjPJg5M8fpH5J1n6GN0ttf6X2h8AtlkCDIC18b4a2jM4LsMJ/vN7mLFvkr9qrf2stXZikv9I8tj+nl8kuVlV7dFau6SHEZvi7RkuSFJVu2QIUOYuWP8wybNaa99vrf08yaFJHlYLV6E+KMmHW2sXZLiIvl9VXTtJ+vPc+yfZM8PFwnn9bulSQcZZGS7Kp3l0kpe21k5vrV2S5K8zPLqykireP0vygQy1PR6Z5KjebyGPSPLy1tr3WmvnJ/mnuQH9IvQOSf62hyjH9mlfQb/DfL8kT2ut/aS19sMMF9CPXGze/Q713N+n5ga01t7SWvtRa+3S1tpLklwlyVw7DivZVv4wyT+11r7WWrs0yfOT7FMTtTD68PNbaz+d6PeC1tqFvUbNpzJcgC/X0+d9rqXaGzmztfbvPeA6PMn1klxnYvgbW2vf7OU7clpZangs6X5JntRau6DX+pl2cb2oZazHX2R4lOn6fT9eqAHSR2cIBd7ey/Kj1tqJvbbBgUn+utdaOiPJS7LhOLAcSy6Pec5qrb2yb0s/zbCMf2/urn+f95sXeO8x2RBY3C3D/jH3+u6ZHmD8IkNwcbPW2mWttRNaaxdtwj7yiCTP69vm95L8yyKfcaXHz/nLZJoX9nl/N8nL04+rm2OZ63+p/QFgmyXAAFgbB7TWdmut3ai19sf9BPn6Sc5vrV08Md6ZGQKAJHlCkl9N8vVe5foBmzjvtyV5aA3tVTw0yZdaa2f2YTdK8t65C8skX0tyWaacHFfV1ZI8PMlbk6Tfufxuhru/6f0+11p7RGttXYaLm/2SPGuJ8u2Z5PwFhl0/wzKZc2aSHaeVbwlvynBX8wqPjywwz+/Nm+fksAtaaz9ZYPikGyXZKcnZE8v33zLc4V3IkX07mfu7x9yAqvqLGh77+HGf1q7Z8PjKSraVGyV5xUSZzk9S2bDdJRt//jk/mOj+3wy1YZbrxfM+12J3zjeaV2vtf3vnztOGL1KWG2TYvza3vZOl1uMzMiy/L9TwKxgL3ZW/QZJpjzrtkaHWxPztfM8p4y5kpetmo/XbWvt8hppad6+qW2aoDXHUAu89Jsndquq6GR7hOiLJXWtorHfXbKhVMunNST6a5B01PM7zoqraKSvfRxbbN+db6fFz2ja/2Dhn9vJsruWs/6X2B4BtlkaJAMbjrCS7V9UuEyHGDZP8T5K01k5L8qh+V/ShSd5VVdeaMp02pd+Gga19tarOzHCnc/LxkWQ4IX98a+0zyyjvQ5JcI8lrqmqumvxuGUKBl0+Z7xer6j3p7X1M0z/bA5N8YoFRzspwkTPnhhmqm5+zjPJO+nSGu5YtQy2YxR45OTvDxebkPCeHXbOqfmUixLhhpq+D7yX5eZI9ek2HTdYf3fmrJPdKcmpr7ZdVdUGGC+fFtpWFyvW81tpbF5nlotvUKprlfL6XYf/arbW21K+5LFaORddja+0HGR47SlXtm+QTVXVsa+1bU6ZzxynTPy8banF8tfe7/DiQIVi4+sT41138o2xcvBX0PzzDYyQ/SPKu1trUWkqttW9V1f9mePzs2NbaxVX1gySHJDmutfbLKe/5RZLnJHlODzo+lOGRiA9lZfvI3L4513DvDRcacYX7RBbpP2n+vM/q3Uuto8WmvdT6B9iuqYEBMBK9CvRnk/xTDY3c3SbDXcO3Jpc3kLeuXxDMXYBN+1nHczI8O72Yt2W44NgvyTsn+r82yfPmHh+oqnVV9eAFpnFQkjck+Y0MVdT3SXLXDI8f/EYNDRT+wdwjJf1O7oOSXKHqdlXtVFW3yvAoy3WTvHT+ON3bk/xZDQ1n7pzhcYcjVhoItNZahqDkQb17MUcmeUpV7VVV10zyzInpnJnk+AwXYlfuF6wPnDaR1trZGdpGeElVXaOGBklvWlV3nzb+EnbJENycm2THqvq7DGFSkkW3lXMz/ArM5Pbx2iR/XVW/1t+7a1U9fBPKtBqmlW9V9OX/4QyB2zX7NrffAqMvuA8ttR6r6uFVtVcf/YIMF6vT9tO3Jrl3VT2ihsYdr1VV+/THAo7MsB/u0vfFP08y1yjkiRnacLlhVe2a4TGq5VrJ8n1zhpDyMVm6ltIxSZ6cDY+LHD3v9UZqaBPnN/rjEhdluGC/bBP2kSMzbLvX7Mv8Txcq4Ar3ieX6yz7vGyR5aobaJ8nS62ix7Wup9Q+wXRNgAIzLo5LsneFO3nuT/H1r7eN92H2TnFrDr228IskjF7gr+ooM7VZcUFULPRP+9gztU/xXa+28ee89KsnHquriDGHDnea/uar2zHD3/+WttR9M/J2Q5CMZwo0LMwQWp/Qyf6R/pslGEQ/swy7s8/1Rktu31s7KdG/IcGF1bJLvZGi7YsGLlsW01k5twy+fLOXfM1R3PylDw6TvmTf89zIso/MzNCq42MXe4zJUD/9qhovbd2WoCbKQA2v4pYLJv2v38nw4yTczVC//WTauzj51W+nVzZ+X5DO9iv6dW2vvTfLCDNX5L0rylWz8M7Oz8Ix5n+m85PLq8BuVb5Xn+9gMF8tfT/LDJE9bYLx/SvLsXoZpDYIuth7vkOTzfdkfleSprbXvzJ9Abzfh/hl+cef8DBe9cz8n+6cZ7uKfnqGG0NsybPvpx4MjkpycofHYDy7zs69o+bbWvp9he28Zaiwt5pgModqxC7ye77oZltlFGR5TOyYbLtBXso88J8P2/50MwcdC7XQkK9gnFv+oG3l/hnVwYpL/TPL6ZFnraKlj9ILrH2B7V0vfeAIAYHtTVW/I0Jjls9e6LACQaAMDAIB5etsUD83wU6YAMAoeIQEA4HJV9dwMjxL987THXwBgrXiEBAAAABg9NTAAAACA0dsq2sDYY4892t57773WxQAAAABm7IQTTjivtbZufv+tIsDYe++9c/zxx691MQAAAIAZq6ozp/X3CAkAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABi9Hde6AKvp/r/xR2tdhG3Ch07517UuAgAAAGxEDQwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGL0dZznxqjojycVJLktyaWttfVXtnuSIJHsnOSPJI1prF8yyHAAAAMDWbUvUwLhHa22f1tr6/vqZST7ZWrt5kk/21wAAAAALWotHSB6c5PDefXiSA9agDAAAAMBWZNYBRkvysao6oaoO6f2u01o7O0n6/2tPe2NVHVJVx1fV8eeee+6MiwkAAACM2UzbwEhy19baWVV17SQfr6qvL/eNrbXXJXldkqxfv77NqoAAAADA+M20BkZr7az+/4dJ3pvkjknOqarrJUn//8NZlgEAAADY+s0swKiqX6mqXea6k9wnyVeSHJXkoD7aQUneP6syAAAAANuGWT5Ccp0k762qufm8rbX2kar6YpIjq+oJSb6b5OEzLAMAAACwDZhZgNFaOz3Jbaf0/1GSe81qvgAAAMC2Zy1+RhUAAABgRQQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6Mw8wqmqHqvpyVX2wv75xVX2+qk6rqiOq6sqzLgMAAACwddsSNTCemuRrE69fmORlrbWbJ7kgyRO2QBkAAACArdhMA4yq2ivJ7yT5j/66ktwzybv6KIcnOWCWZQAAAAC2frOugfHyJM9I8sv++lpJLmytXdpffz/JnjMuAwAAALCVm1mAUVUPSPLD1toJk72njNoWeP8hVXV8VR1/7rnnzqSMAAAAwNZhljUw7prkQVV1RpJ3ZHh05OVJdquqHfs4eyU5a9qbW2uva62tb62tX7du3QyLCQAAAIzdzAKM1tpft9b2aq3tneSRSf6rtfboJJ9K8rA+2kFJ3j+rMgAAAADbhi3xKyTz/VWSP6+qb2VoE+P1a1AGAAAAYCuy49KjbL7W2tFJju7dpye545aYLwAAALBtWIsaGAAAAAArIsAAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjN7MAo6quWlVfqKqTqurUqnpO73/jqvp8VZ1WVUdU1ZVnVQYAAABg2zDLGhg/T3LP1tptk+yT5L5VdeckL0zystbazZNckOQJMywDAAAAsA2YWYDRBpf0lzv1v5bknkne1fsfnuSAWZUBAAAA2DbMtA2Mqtqhqk5M8sMkH0/y7SQXttYu7aN8P8meC7z3kKo6vqqOP/fcc2dZTAAAAGDkZhpgtNYua63tk2SvJHdMcqtpoy3w3te11ta31tavW7dulsUEAAAARm6L/ApJa+3CJEcnuXOS3apqxz5oryRnbYkyAAAAAFuvZQUYVfXJ5fSbN3xdVe3Wu6+W5N5JvpbkU0ke1kc7KMn7V1JgAAAAYPuz42IDq+qqSa6eZI+qumaS6oOukeT6S0z7ekkOr6odMgQlR7bWPlhVX03yjqr6xyRfTvL6zfkAAAAAwLZv0QAjyR8meVqGsOKEbAgwLkry6sXe2Fo7OcntpvQ/PUN7GAAAAADLsmiA0Vp7RZJXVNWfttZeuYXKBAAAALCRpWpgJElaa6+sqt9Ksvfke1prb5pRuQAAAAAut6wAo6renOSmSU5Mclnv3ZIIMAAAAICZW1aAkWR9klu31tosCwMAAAAwzbJ+RjXJV5Jcd5YFAQAAAFjIcmtg7JHkq1X1hSQ/n+vZWnvQTEoFAAAAMGG5AcahsywEAAAAwGKW+yskx8y6IAAAAAALWe6vkFyc4VdHkuTKSXZK8pPW2jVmVTAAAACAOcutgbHL5OuqOiDJHWdSIgAAAIB5lvsrJBtprb0vyT1XuSwAAAAAUy33EZKHTry8UpL12fBICQAAAMBMLfdXSB440X1pkjOSPHjVSwMAAAAwxXLbwPj9WRcEAAAAYCHLagOjqvaqqvdW1Q+r6pyqendV7TXrwgEAAAAky2/E841Jjkpy/SR7JvlA7wcAAAAwc8sNMNa11t7YWru0/x2WZN0MywUAAABwueUGGOdV1WOqaof+95gkP5plwQAAAADmLDfAeHySRyT5QZKzkzwsiYY9AQAAgC1iuT+j+twkB7XWLkiSqto9yYszBBsAAAAAM7XcGhi3mQsvkqS1dn6S282mSAAAAAAbW26AcaWquubci14DY7m1NwAAAAA2y3JDiJck+WxVvStJy9AexvNmVioAAACACcsKMFprb6qq45PcM0kleWhr7aszLRkAAABAt+zHQHpgIbQAAAAAtrjltoEBAAAAsGYEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABi9mQUYVXWDqvpUVX2tqk6tqqf2/rtX1cer6rT+/5qzKgMAAACwbZhlDYxLk/xFa+1WSe6c5E+q6tZJnpnkk621myf5ZH8NAAAAsKCZBRittbNba1/q3Rcn+VqSPZM8OMnhfbTDkxwwqzIAAAAA24Yt0gZGVe2d5HZJPp/kOq21s5Mh5Ehy7QXec0hVHV9Vx5977rlbopgAAADASM08wKiqnZO8O8nTWmsXLfd9rbXXtdbWt9bWr1u3bnYFBAAAAEZvpgFGVe2UIbx4a2vtPb33OVV1vT78ekl+OMsyAAAAAFu/Wf4KSSV5fZKvtdZeOjHoqCQH9e6Dkrx/VmUAAAAAtg07znDad03y2CSnVNWJvd/fJHlBkiOr6glJvpvk4TMsAwAAALANmFmA0Vo7LkktMPhes5ovAAAAsO3ZIr9CAgAAALA5BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0BBgAAADA6AkwAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHozCzCq6g1V9cOq+spEv92r6uNVdVr/f81ZzR8AAADYdsyyBsZhSe47r98zk3yytXbzJJ/srwEAAAAWNbMAo7V2bJLz5/V+cJLDe/fhSQ6Y1fwBAACAbceWbgPjOq21s5Ok/7/2QiNW1SFVdXxVHX/uuedusQICAAAA4zPaRjxba69rra1vra1ft27dWhcHAAAAWENbOsA4p6qulyT9/w+38PwBAACArdCWDjCOSnJQ7z4oyfu38PwBAACArdAsf0b17Un+O8ktqur7VfWEJC9I8ttVdVqS3+6vAQAAABa146wm3Fp71AKD7jWreQIAAADbptE24gkAAAAwR4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDo7bjWBWD78Dv3/du1LsI24T8/8ty1LgIAAMCaUAMDAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAo+dnVGE7du9H+1nW1fCJt/qZYAAAmDU1MAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD2/QgIwQr/1ZL8Qs7k++6rV/3WY2z/rH1Z9mtujE573d2tdBABgK6QGBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOgJMAAAAIDRE2AAAAAAoyfAAAAAAEZPgAEAAACMngADAAAAGD0BBgAAADB6AgwAAABg9AQYAAAAwOjtuNYFAADYHLd98d+vdRG2CSc9/TmrPs19D3vWqk9ze3Tcwc9b1en9/of/fFWnt7164/1euurTfOFxj1n1aW6P/mrft6zq9D7w+X1XdXrbqwfe6bjNnoYaGAAAAMDoCTAAAACA0RNgAAAAAKMnwAAAAABGT4ABAAAAjJ4AAwAAABg9AQYAAAAwegIMAAAAYPQEGAAAAMDorUmAUVX3rapvVNW3quqZa1EGAAAAYOuxxQOMqtohyauT3C/JrZM8qqpuvaXLAQAAAGw91qIGxh2TfKu1dnpr7f+SvCPJg3rJs0oAABTqSURBVNegHAAAAMBWolprW3aGVQ9Lct/W2hP768cmuVNr7cnzxjskySH95S2SfGOLFnR29khy3loXgqmsm3GyXsbJehkv62acrJfxsm7GyXoZL+tmnLa19XKj1tq6+T13XIOC1JR+V0hRWmuvS/K62Rdny6qq41tr69e6HFyRdTNO1ss4WS/jZd2Mk/UyXtbNOFkv42XdjNP2sl7W4hGS7ye5wcTrvZKctQblAAAAALYSaxFgfDHJzavqxlV15SSPTHLUGpQDAAAA2Eps8UdIWmuXVtWTk3w0yQ5J3tBaO3VLl2MNbXOPxWxDrJtxsl7GyXoZL+tmnKyX8bJuxsl6GS/rZpy2i/WyxRvxBAAAAFiptXiEBAAAAGBFBBgAAADA6I06wKiqvavqK/P6HVpVT1/ifeur6l969/5V9VubMO8zqmqPBYbdrqpaVf2/lU53qWlPjHNwVZ1bVSdO/N16BfN4UlU9boXl2qRltVr6Mn3JxOunV9Whqzj9P5m3PL/S53mrTZzeJatUrits52NWVQ/py+2WE/3+uapOrap/XuR9+1fVB1epDJfv4wsM37uqfm815jVGYzw2VtXjq+qUqjq571sP7v0PrqrrL2O6yxpve7I5x5jlbA/bmpHuF5f3r6rbV9V3+jnEg6rqmSudzwLzXrVj67agqi6b912/Kst5Yvr7VNX9V3OaY1dVz+rf8Sf3ZXqnVZru0VW1vnd/qKp2W2C8mZx3b8q58vZgtc5vWbkpx6+917pMY7TFG/HcElprxyc5vr/cP8klST67irN4VJLj+v+Pzh9YVZWhfZFfbuZ8jmitPXlT3thae+20/lW1Y2vt0gXetn9Wf1mtxM+TPLSq/qm1dt5qT7y19uokr557XVXPT3Jia+1rqz2vbdzc9v/IJIf2fn+YZF1r7edbogDz9vFp9k7ye0netiXKs7WY1bGxqvZK8qwkv9la+3FV7ZxkXR98cJKvZOmfy17ueMxTVTu01i5b63JsrbbAOUOq6jZJ3pXkwNbal5N8OX6BbVZ+2lrbZ4bT3yfJ+iQfmuE8RqOq7pLkARmO7z/vQcCVV3s+rbXFQqGZnHcvdK7MFfme2WIWPX4tcR233Rh1DYyl9OT2hVX1har6ZlXdrfffv6o+2FOrJyX5s55i3a2q1lXVu6vqi/3vrv0916qqj1XVl6vq35LUAvOsJA/LcLJ9n6q6au+/d1V9rapek+RLSW5QVf9aVcf31Po58yb1l73cX6iqm63gM+9fVcdU1ZH9M7+gqh7dp3NKVd20j3f5Xae+nJ5fVcckeWpVPbCqPt8/6yeq6jorXFZ3n0gGv1xVuyy3/Eu4NEPruX825XMvVJZTqmq3GvxoLkmvqjdX1b0XWY77JXlEkj/ur3eooRbBF/sdhj/s/Xeuqk9W1Zf6vB48ZVpTx5nYJv69bwMfq6qr9WG3r6qTquq/k/zJZi63LaZfmN41yRMyBBipqqOS/EqSz1fVgVV106r6XF+W/1AbJ/k7V9W7qurrVfXWvj+lqv6uj/+VqnrdRP9F9/HePW17fEGSu/V+f9bXxaf7OvpS9TusfTpHTyvT1myp5bbC/X05x8ZrJ7k4w4VfWmuXtNa+U1UPy3Ci/9Y+n6tNW9cLjHf7Go51J1TVR6vqer08T6mqr/b99B2zXZJrry+ff+7L65SqOrD337+qPlVVb0tySu/3rKr6RlV9IsktJqbxB32Zn9TX8dV7/8Oq6l+q6rNVdXpfD9usNdgv5twqyfuSPLa19oX+/oOr6lW9e+p6qKorVdVravj++GANd6jnht23H7OOS/LQic+4e1W9r+8fn6shOJk7Jzi8l/mMqnpoVb2ob1MfqaqdVnVhj1BV3X9umfXl/cG+jE+rqnV9nCtV1beqao++Xl5bw3fHN6vqAVV15ST/kOTAvo0cuLafaou4XpLz5m5QtNbOa62dlSz53T1Xs2KPqjqjd1+tqt7Rt88jklxtbia1cC2JmZ1318bnylOPk9uzBb5n3lfD9/KpVXXIxLiXVNXz+vL7XFVdZ80Kvo3p3xfvrKoPJPlYbdp1x81quOY7qb9v7nrxL2vDtc/8fWa8Wmuj/ctwF/Ur8/odmuTpvfvoJC/p3fdP8onevX+SD84fv79+W5J9e/cNk3ytd/9Lkr/r3b+TpCXZY0qZ9k3yyYlpPXSirL9McueJcXfv/3foZb1Nf31Gkmf17sfNlXXefA5Ocm6SEyf+rtY/24UZvlCukuR/kjynv+epSV6+wHJ6zcS0r5lc/gs0T5xYhstdVh9IctfevXOSHVdpfV+S5Bp9+eya5OlJDl2iLK/t6+vXk3wxyb/3/qcl2XmB+eyW5Ntzn6H3OyTJs3v3VTLcjbtxhlpK1+j990jyrYlld0n/P3Wcvk1cmmSfPuzIJI/p3ScnuXvv/ufM287H+pfkMUle37s/m+GOzOXLond/MMmjeveTJpbT/kl+nGSvDOHpf0+s090n3v/mJA9cwT5+he1xcnjvf/UkV+3dN09y/FJlGvNfRnZszHCM+2iS7yZ549z6myjL+onXi63r9b17p759reuvD8zwk9vJUEPjKr17t7VeFzNez5ck+d0kH+/L+Dp9GV+vr8ufJLlxH/f2GU4wr57hOPqtie3hWhPT/Mckf9q7D0vyzr7t3zrJt9b6M2/m8hrVftGHnZHk/CT3n9f/4CSvWmw9ZLho+1Dvf90kF/R+V03yvQzHssrw3TJX/lcm+fvefc8MtQznPtdxfd+6bZL/TXK/Puy9SQ5Y6/W3itvBZdn43OnAiWU2t7+8fWKZ/X2Sp/Xu+yR598R6+Uhf/jdP8v0+ncvX3fbwl+F79cQk30zymvRzlz5sOcfzPZKc0bv/PBuO5bfJcI40N94ZC+xDMzvvzsbHh6nHye3xLxuft13+PTNvGV8tQ63Ja/XXbWL9vyj9nNrfipf95PHrvb3fwf34M7fsN+W64/NJHtK7r5rhXOE+GW4cVz/OfTDJfmu9DJbzN/ZHSNoy+r+n/z8hw4pbyr2T3Lo23GS9Rg13bPdLv4vRWvvPqrpggfc/KsncXb93JHnsRBnObK19bmLcR/R0cscMJ5y3znDhmgxfnnP/X7bAvK7wCEkv9xdba2f3199O8rE++JQk91hoWhPdeyU5ooY7mldO8p0F3rPQsvpMkpdW1VuTvKe19v0F3r9irbWLqupNSZ6S5KfLKMunM6y7M5P8a5JDqmrPJOe31hZ6hu9fk7yltfaZiX73SXKb2nAHctdsOGF5fg01Nn6ZZM8MFxE/mHhvLTBOknyntXZi7z4hyd5VtWuGC69jev83J7nfEotmLB6V5OW9+x399ZfmjXOXJAf07rclefHEsC/MbS9VdWKGffa4JPeoqmdkOKDunuTUDMFEsvQ+foXtsa5YiWKnJK+qqn0yfDn86jLKNGajOja21i6rqvsmuUOSeyV5WVXdvrV26JT5LLau59wiQyj58V6eHZKc3YednKGmxvsy3NXe1u2b5O1tqLp7Tg016e6Q5KIM2+7c8ftuGU52/je5vGbUnF+vqn/MEN7unI2rYL+vDdWuv7oN3DEb1X4x4RNJnlhVH20LV8Geth72TfLO3v8HVfWp3v+WGb5bTkuSqnpLhhB+7j2/28v1XzXUFNm1D/twa+0XVXVKhn3qI73/KVnesthaXKEKdj/2nz6xv7w9G5bZG5K8P8N32+MzhLBzjuzL/7SqOj3Dst+utNYuqarbZzjG3CPD+eMzW2uHZXnH80n7ZQj/0lo7uapOXmTcOVvqvHux4+T2bPJ7JkmeUlUP6d03yHCu/KMk/5fhAjgZjq+/veWKuE1Z6BGSj7fWzu/dK73u2CXJnq219yZJa+1nSVJV98lw/fPlPv7OGdbnsav8mVbd2AOMH2WoLTBp92x8wT33zP1lWd7nuVKSu7TWJi+O54KBhU5+5sbZIcOJwYOq6lkZNqBr1YZHKH4yMe6NM9QguENr7YKqOixD4jWnLdC9HJPtDPxy4vUvs/Ay+MlE9yuTvLS1dlRV7Z8N7RjMN3VZJXlBVf1nhjtYn6uqe7fWvr6C8i/l5RkuiidPIhZab8dmeATjhhmewX9IhjtUn5424ao6KMOJ2mPnD8qQtn903vgHZ3iW//b9xO+MbLwek+TRi4wzua4uy5BYV1a+ztdcVV0rwx29X6+qluEEuPWTl+Wavzx2rKE66Gsy3IX5Xg0Nt151ynum7uOttStsj1Pm+2dJzslw5/FKSX62WJlW8HnWyqiOjUnShlj/C0m+UFUfz7D/HjpvWkut68tHTXJqa+0uU4b9ToaT4Acl+duq+rW2bT8PutijCT+Z93qh9XRYhjvsJ/Vj2v4Twya3/6398anR7RfdkzPUFnxNhvaCppm2HhZbHwvNe9p75sadewTgl1X1i77PJoufO2wrFlyW/Vh0TlXdM8mdMnynXz54/uizKNzY9eDt6CRH9wDsoBoe4VvoeH5pNjymPv8Yv+xluIXPuw/LwsfJ7dnkMt4/Q6h7l9ba/1bV0dmwjCePKVvLudTWZPL7flOuO6apJP/UWvu3VS7rzI26DYx+B/3sqrpXMjzbmeS+Wdnd0YuTTLbR8LEMJxPp05xLuY5N/9KqqvvliidBybDTntRau0Frbe/W2o2SvDsb7jZPukaGje3H/W7K/DvsB078/+8VfJ7VsGuGR0+S5KCJ/staVlV109baKa21F2Z41GJV70j0hPHIDO0sLFqW1tr3MlSfunlr7fQM28bTMyXAqKqbJHlekkdPueD5aJI/qv4ccFX9alX9SoZl9cN+gLhHkhtNKfJyxpn8fBdm2C727b0evdj4I/KwJG9qrd2ob/83yHBhsO+88T6XfgcwvZ2MJcwddM+roY2NFT2Hv8D2OH9b3jXJ2f1O2mMzhC9brbEdG6vq+lX1mxO99slQK2r+fBZb15PjfSPJuhoaj0tV7VRVv1ZVV0pyg9bap5I8IxvulG3Ljs3wvP0ONTynv1+GoGjaeA+p4RnzXZI8cGLYLhm2l52y9RxvVmxs+8WEX2a4i3yLqvqHFZTluCS/W0O7DNfJhguqrye5cfVnmPu050yWa/8MbRdctIJ5bqu+nuQmtaFF//ltV/xHkrdkqHExWUvm4X353zTJTTIcm+ZvI9u0qrpFVd18otfc8X2x4/kZGR5ry7z+k9vnr2d4jGQxW/K8e7s4Tm6mXZNc0MOLWya581oXaDu10uuOi5J8v6oOSJKqukoNbbx8NMnj+/6bqtqzqq4947KvilEHGN3jkjy7hqrd/5WhvYdvr+D9H8hwUndiDQ12PSXJ+hoaK/lqhmf0k+Q5Sfarqi9lqE7z3SnTelSGZ0UnvTvDrx1spLV2UoYqOadmqJ74mXmjXKWqPp+h3YorNFrZzTUSNfe3Wj9xemiSd1bVp5NM/trHcpfV02posOmkDI95fHiVyjXpJRmCiTkLlSUZnuv6Zu/+dIaqVNNOWP8qQ2OT75m3XO+W4eTlq0m+VMPP8P1bhvT4rX2+x2f4QptW02Q548z3+0leXUMjnvNruIzVcrf/pyX586r6QoYqnD9ebKI90Pn3DNWY35ehLZOVmLY9npzk0hoaK/qzDHeJDqqqz2V4fGT+neut0ZiOjTsleXENDeTNPXP+1D7ssCSv7f1/noXX9eR4O2Q46X1hX68nJvmt3v8t/Q7gl5O8rG8/25yq2jHD8npvhu35pAzr+RmttR/MH7+19qUMjwqemGG/nAxx/zbDcfLjWd7xaWs2pv3icm1oAPHBGe4kL7fh5ndneIxx7jvp80l+3Kv/HpLkP2toxPPMifccOlfeDI0ZH5Ttz9Xmfce/oNeg+eMkH+nL7Jxs/N10VIYw9I3zpvWNJMdk+F55Ul/2n8rwWNH20ojnzkkOr954cobHMg5d4rv7xRluCn02G5/L/WuGxrxPzhBCTwtjJ23J8+7t6Ti5qT6SoebsyUmem+GGFVveplx3PDbD4z8nZ2hj7LqttY9leNT7v/t51buylYSzc40RAqyKnur+tLXWquqRGRr0vMKvtwALq6rbZmiU+I5rXRbWTlXt3NsguFaGi727TguwWNrEsqwMP6l+WmvtZX3Y+gyB6N0mxj8sQ2OP71qTAgMwleeTgNV2+wwNZlaGX8x5/BqXB7YqVfWkDHf+n7bWZWHNfbCqdsvQ4PZzhReb5Q9qaAfryhnu1P9bklTVM5P8UTw2ALBVUAMDAAAAGL2toQ0MAAAAYDsnwAAAAABGT4ABAAAAjJ4AAwDYLFV13ap6R1V9u//c4oeq6ldXcfr7L/ZT4lX1oN4YIwCwDdOIJwCwyfovDn02yeGttdf2fvsk2aW19ulVmsehSS5prb14yrAdW2uXrsZ8AIBxE2AAAJusqu6Z5NDW2n7z+leSFyW5X5KW5B9ba0dU1f5Jnt5ae0Af71VJjm+tHVZVZyQ5PMkDk+yU5OFJfpbkc0kuS3Jukj9N8oQk5ye5XZIvJTklyfrW2pOral2S1ya5YS/K01prn6mquyd5Re/XkuzXWrt4tZcHADA7O651AQCArdqvJzlhSv+HJtknyW2T7JHki1V17DKmd15r7Ter6o8zBB1PrKrXZqIGRlU9IcmvJrl3a+2yqjp44v2vSPKy1tpxVXXDJB9NcqskT0/yJz3M2DlDMAIAbEUEGADALOyb5O2ttcuSnFNVxyS5Q5KLlnjfe/r/EzKEIAt5Z5/2fPdOcuuhAkiS5BpVtUuSzyR5aVW9Ncl7WmvfX+bnAABGQiOeAMDmODXJ7af0ryn9kuTSbHz+cdV5w3/e/1+WxW+0/GSB/ldKcpfW2j79b8/W2sWttRckeWKSqyX5XFXdcpFpAwAjJMAAADbHfyW5SlX9wVyPqrpDkguSHFhVO/R2KfZL8oUkZ2aoIXGVqto1yb2WMY+Lk+yyzPJ8LMmTJ8qyT/9/09baKa21FyY5PokAAwC2Mh4hAQA2WWutVdVDkry8/5Tpz5KckeRpSXZOclKGRjOf0Vr7QZJU1ZFJTk5yWpIvL2M2H0jyrqp6cIZGPBfzlCSvrqqTM5znHJvkSUmeVlX3yFCz46tJPrySzwkArD2/QgIAAACMnkdIAAAAgNETYAAAAACjJ8AAAAAARk+AAQAAAIyeAAMAAAAYPQEGAAAAMHoCDAAAAGD0/j/3vqtTstLYgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAGoCAYAAACwmRWfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdebgkZX0v8O9PwBVcmagoilGiIblKdCQaN9zBXeNVuC5woyEmmmhuTGKiUdQkGhM1GjSGqAFRUROXYMSFq8ElrgMCgrsEBVEZxA23K/i7f1QdaA59Zs4Mc86pYT6f5+mnq6veqnq7qrq669tvVVV3BwAAAGDKrrLWFQAAAADYHAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AA2MFV1c2q6sKq2mkTZS6sql9czXqthap6eFWdPb7fX1vjupxVVfdZhfm8u6oOWen5LKMee1VVV9XOWzn+GVW1/zLKbXJbXu50mK+q7lZVX1iF+XRV3WrsflVV/cU2mu5l9odVdWJVPXFbTHuc3iQ+bwDbKwEGwHZmPLD98fgj+1tV9S9VtevWTq+7v9bdu3b3xeP0L/eDfRx+5hWt+zxVdYuq+nlVvXLOsIdW1SlV9f2qOr+q3l9Ve43DDq+qn1XVD8bHF6vqiKq68RWozt8lecr4fj+9JfW5IqrqqKr6y20wnf3HA7s/We443X1gdx99Rec9py6HVtXF43Y6+9hjHL5NA5ru/pXuPnEZ5S7Zluct9+VOZ+pWKwBbrLs/3N23XuV5Pqm7n7+5cstZJov3h1fEuI96/aLpr8jnDWBHIcAA2D49uLt3TXL7JHdM8qw1rs8V8fgk30lyUFVdbaHn+O/q65L8UZLrJLlFklcm+fnMuG/u7t2SXD/Jw5PcKMlJVyDEuHmSM+YNWGZ91tohSS4Yn6fgY+PB4Ozj3LWuFMnWtnS5MrNMAKZPgAGwHevuryd5d5JfTZKq2qOqjquqC6rqy1X12wtlq2q/qtowth74VlW9ZOx/SdP9qvqrJHdLcsT4b/kRY5muqltV1Z2q6puzp5uMp12cNnZfpaqeUVVfqapvV9Vbqur6m3kbj88QwPwsyYNn+u+b5L+7+/09+EF3v7W7vzZnOfysu89I8ugkGzOEDJcz1u9ZVfXVqjqvql5XVdepqqtV1YVJdkpyalV9Zc7om6zPOI2/r6pzx8ffLwQyY2uEjyyqy8IyPSzJY5L8ybjM3zk7z6o6raq+V1VvrqqrL7UQq+qaSR6Z5MlJ9q6q9TPDrl5Vrx/XyXer6lNVdcNx2CUtbqrqllX1gbHc+VX1hqq67sx0zqqqpy+3Tpuo6zFJbpbkneN7nm0x8piq+to4/2fOjHP4uD29bmxxc8ai93jJv+tVtVNV/fm4Hf6gqk6qqj2Xs9wXTWfJ7XlTy3TO+92zqt5WVRvH8kfMTP9y2+M4bP+qOmfRdGbrtuTymLd869LP+ROq6mtJPlBV76qq3180j9Oq6mFz3sPRVfVHY/dNxmn93vj6VjXsc2pxvavqT6vq62Mdv1BV997csl1iGf5xVX2jhs/Wby0adklLmqravar+Y1wnF1TVh8d5LXeZzDuV6ZZV9clxm//3mW1gyXVUVQck+fMkjx7nd+o4fPbztqn1v1CPQ2rO5wFgRyXAANiOjQdlD0iycLrDsUnOSbJHhoPZv144YEjysiQv6+5rJ7llkrcsnl53PzPJh3PpaRRPWTT840l+mOReM73/V5I3jt1/kORhSe4x1uE7SV6xifrfLclNk7xprM/jZwafnOQ2VfXSqrpnLeM0mbHZ979nCGHmOXR83DPJLybZNckR3f3TsUVLktyuu285Z9zN1eeZSe6UIei4XZL9soyWMd19ZJI3JHnRuMxnQ5xHJTkgQ2uP2451X8pvJrkwyb8meW8uuywPydBqZM8kN0jypCQ/njONSvKCDOvul8fyhy8qsyV1mqu7H5fkaxlbEnX3i2YG3zXJrZPcO8mzq+qXZ4Y9JMO2ct0kxyU5YolZ/J8kB2f4bFw7yW8l+dGiOmxquS/Y1Pa8rGVaQ9j3H0m+mmSvJDcZ30OyxPa4xHuaZ+7y2MzyvUeGdXv/JEcneexMXW831u/4OfP6YJL9Z6Zx5vicJHdP8uHu7tkRqurWSZ6S5I5jS6n7JzlrHLzsfcUYBjw9yX2T7J1kU6eB/FGGfeC6JDfMECL0FiyTeR6fYRvaI8lFSV6+ifknwwzfk+SvM7QS27W7bzen2KHZ/Prf1OcBYIcjwADYPr2jqr6b5CMZDiz+egwz7prkT7v7J919SpJXJ3ncOM7Pktyqqnbv7gvHMGJrHJvh4DBVtVuGg8Rjx2G/k+SZ3X1Od/80w8HvI2vpptmHJHl3d38nQwhyYFX9QpKM1ynYP8MB1VuSnD/+07q5IOPcDKeUzPOYJC/p7jO7+8Ikf5bh1JXNNh1fRn0ek+R53X1ed29M8txcuuy31su7+9zuviDJOzOEI0s5JMPB0sUZluXBVbXLOOxnGQ6yb9XdF3f3Sd39/Tnv8cvdfcIY6GxM8pJcepC6NXW60/hP+MJjXsuWxZ7b3T/u7lOTnJohDFrwke4+fnyPxywaNuuJSZ7V3V8YW8uc2t3fXsa8F9vU9rysZZohyNojyR939w/Hz+ZCa5yt3h5Hy10esw4f6/HjDGHf3lW19zjscRm2of83Z7wPJrlbVV0lQ2DxoiR3GYfdYxy+2MVJrpZkn6rapbvP6u6FbWBL9hWPSvIv3X16d/8wlw/VZv0syY2T3HxsmXW5YGWO2WUyzzEz8/6LJI+qTVz0eAssZ/1v6vMAsMMRYABsnx7W3dft7pt39++NP7z3SHJBd/9gptxXMxxwJ8kTkvxSks/X0Nz9QVs57zcmeUQNp0c8IsnJ3f3VcdjNk7x94YA1yecyHMRcrml9VV0jyf/M8C94uvtjGf4h/V8LZbr74939qO5el6FVxd0ztHTYlJtkuA7EPHtkWCYLvppk53n1m2cz9Zk37T2WM91N+OZM948y/EN7OWN4dc+MyzLDgenVkzxwfH1MhlYZbxqb4L9oJtyYnc4vVNWbxib/30/y+iS7b02dRh8ft9OFx7yWLYttavqLh119iQPePZMsJyzZnE1tz8tapmNdvtrdF80ZdoW2xyx/ecw6e6FjDA7ekuSxYzBxcIb3dTlj8HBhhsDqbhlalZw7trKYG2B095eTPC1D4HDeuG0tfCaWva/IsJzOnnn91TllFvxtki8neV9VnVlVz9hE2QVnb8HwrybZJZf/XGyN5az/Lfm8AVzpCTAArjzOTXL9sVXEgpsl+XqSdPeXuvvgJL+Q5G+S/FtVXWvOdDb5b2V3fzbDD+0Dc9nTR5Lhh/6Biw5ar97DtToWe3iG5v2vrOG6Gt/MED48fk7ZdPenkrwt4/U+5hkPwh6c4TSYec7NcOC04GYZmoR/a6lpLmVOfeZNe+GClT9Mcs2Zet5o8eS2dP6LPC7Dd/o7x+V4ZoYA4/FjXX/W3c/t7n2S/EaSB2X+cn7BWJfb9nCq0WMznFayEq7oe96UszOcJnVF67Dk9rwFy/TsJDdbIljY1Pa4eJvZKcNpEcu11Htb3P/oDC0B7p3kR2OQuJQPZjg17arjZ/qDGd7z9ZKcMndm3W/s7rtmeJ+dYd+TbNm+4hsZgqAFN1uqgj1cm+aPuvsXM+wL/s/MaXTLXSaLLZ73z5Kcn82vo81Nd5vtjwB2FAIMgCuJ7j47yUeTvKCGCwzeNkOrizckSVU9tqrWdffPk3x3HG3erQK/leF87E15Y4Zz2O+e4ZoLC16V5K+q6ubjPNdV1UOXmMYhSV6b5H9k+Fd33wxN0vetqv9RVXetqt9eOKWkqm6T4Zz/y536UlW7jOeGH5vhTiQvWWKexyb5wxpu3bprLj1Hfd6/44vnsbn6HJvkWeN73j3JszO0YEiGpt+/UlX71nDRy8MXTX45y3xTHp/hlJV9Zx6/meSBVXWD8Zod/2M8wPp+hgOweet+twz/sn+3qm6S5I+vQJ0254q+5015dZLnV9XeNbhtVd1gK+qw5Pa8Bcv0kxkOwF9YVdcaP5sLp15sanv8YoYWFQ8cW3Y8K8PpGMu1rOU7BhY/T/LiLNH6YsYHM1zT4kPj6xOT/H6GU1ku996r6tZVda+xtdZPMlwjZKHcluwr3pLk0Krap4aL1T5nqQpW1YNquKhoZVgvF8/Mc2u3ucfOzPt5Sf5tfL+bW0ffSrLXGKzOs9X7I4AdlQAD4Mrl4AwXCjw3yduTPKe7TxiHHZDkjBrutvGyJAd190/mTONlGc5F/05VLXWxumMzXA/iA919/qJxj8vQfPsHGQ7uf33xyOPB8b2T/H13f3PmcVKS92QIN76bISD4zFjn94zvafbie48eh313nO+3k9yhl75V52szHKR9KMl/Zzio+v0lyi62ufr8ZZINSU5L8pkMF/38yyTp7i9mOPD5v0m+lOHaJbNek+E6Ad+tqncssz5Jkqq6U4Z1/opFy/K4DE3pD84Q6vxbhgO6z2U4EH39nMk9N8Oteb+X5F0ZWphcEXeu4Q4Ms487jsNekCHw+W5VPf0Kzmexl2Q46H1fhvf8miTXmFNuc8t9U9vzspbpeKD74CS3ynCK1DkZ7paTbGJ77O7vJfm9DGHM1zP823+ZO15sxpYs39dlCBLnbROzPpgh5FoIMD6SoQXCh5Yof7UkL8zQWuGbGVp//fk4bFn7iiTp7ncn+fskH8iwTX9gE3XcO8Pn7MIkH0vyyu4+cRy2tdvcMUmOGt/D1TOEt8tZRwvh7rer6uQ5070i+yOAHVJt/rpGAABcWVXV45McNp7qAQCTpQUGAMAOajwt4veSHLnWdQGAzRFgAADsgKrq/kk2ZrhWwxs3UxwA1pxTSAAAAIDJ0wIDAAAAmLx59yTfbu2+++691157rXU1AAAAgK100kknnd/d6xb3v1IFGHvttVc2bNiw1tUAAAAAtlJVfXVef6eQAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAydt5rSuwlh54h6eudRWY410nvWytqwAAAMDEaIEBAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPJWLMCoqj2r6j+r6nNVdUZVPXXsf/2qOqGqvjQ+X2+J8Q8Zy3ypqg5ZqXoCAAAA07eSLTAuSvJH3f3LSe6U5MlVtU+SZyR5f3fvneT94+vLqKrrJ3lOkl9Psl+S5ywVdAAAAABXfisWYHT3N7r75LH7B0k+l+QmSR6a5Oix2NFJHjZn9PsnOaG7L+ju7yQ5IckBK1VXAAAAYNpW5RoYVbVXkl9L8okkN+zubyRDyJHkF+aMcpMkZ8+8PmfsN2/ah1XVhqrasHHjxm1ZbQAAAGAiVjzAqKpdk7w1ydO6+/vLHW1Ov55XsLuP7O713b1+3bp1W1tNAAAAYMJWNMCoql0yhBdv6O63jb2/VVU3HoffOMl5c0Y9J8meM69vmuTclawrAAAAMF0reReSSvKaJJ/r7pfMDDouycJdRQ5J8u9zRn9vkvtV1fXGi3feb+wHAAAA7IBWsgXGXZI8Lsm9quqU8fGAJC9Mct+q+lKS+46vU1Xrq+rVSdLdFyR5fpJPjY/njf0AAACAHdDOKzXh7v5I5l/LIknuPaf8hiRPnHn92iSvXZnaAQAAANuTVbkLCQAAAMAVIcAAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMnbeaUmXFWvTfKgJOd196+O/d6c5NZjkesm+W537ztn3LOS/CDJxUku6u71K1VPAAAAYPpWLMBIclSSI5K8bqFHdz96obuqXpzke5sY/57dff6K1Q4AAADYbqxYgNHdH6qqveYNq6pK8qgk91qp+QMAAABXHmt1DYy7JflWd39pieGd5H1VdVJVHbapCVXVYVW1oao2bNy4cZtXFAAAAFh7axVgHJzk2E0Mv0t33z7JgUmeXFV3X6pgdx/Z3eu7e/26deu2dT0BAACACVj1AKOqdk7yiCRvXqpMd587Pp+X5O1J9lud2gEAAABTtBYtMO6T5PPdfc68gVV1rarabaE7yf2SnL6K9QMAAAAmZsUCjKo6NsnHkty6qs6pqieMgw7KotNHqmqPqjp+fHnDJB+pqlOTfDLJu7r7PStVTwAAAGD6VvIuJAcv0f/QOf3OTfKAsfvMJLdbqXoBAAAA25+1uognAAAAwLIJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8lYswKiq11bVeVV1+ky/w6vq61V1yvh4wBLjHlBVX6iqL1fVM1aqjgAAAMD2YSVbYByV5IA5/V/a3fuOj+MXD6yqnZK8IsmBSfZJcnBV7bOC9QQAAAAmbsUCjO7+UJILtmLU/ZJ8ubvP7O7/l+RNSR66TSsHAAAAbFfW4hoYT6mq08ZTTK43Z/hNkpw98/qcsR8AAACwg1rtAOMfk9wyyb5JvpHkxXPK1Jx+vdQEq+qwqtpQVRs2bty4bWoJAAAATMqqBhjd/a3uvri7f57knzOcLrLYOUn2nHl90yTnbmKaR3b3+u5ev27dum1bYQAAAGASVjXAqKobz7x8eJLT5xT7VJK9q+oWVXXVJAclOW416gcAAABM084rNeGqOjbJ/kl2r6pzkjwnyf5VtW+GU0LOSvI7Y9k9kry6ux/Q3RdV1VOSvDfJTkle291nrFQ9AQAAgOlbsQCjuw+e0/s1S5Q9N8kDZl4fn+Ryt1gFAAAAdkxrcRcSAAAAgC0iwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJO3YgFGVb22qs6rqtNn+v1tVX2+qk6rqrdX1XWXGPesqvpMVZ1SVRtWqo4AAADA9mElW2AcleSARf1OSPKr3X3bJF9M8mebGP+e3b1vd69fofoBAAAA24kVCzC6+0NJLljU733dfdH48uNJbrpS8wcAAACuPNbyGhi/leTdSwzrJO+rqpOq6rBNTaSqDquqDVW1YePGjdu8kgAAAMDaW5MAo6qemeSiJG9Yoshduvv2SQ5M8uSquvtS0+ruI7t7fXevX7du3QrUFgAAAFhrqx5gVNUhSR6U5DHd3fPKdPe54/N5Sd6eZL/VqyEAAAAwNasaYFTVAUn+NMlDuvtHS5S5VlXtttCd5H5JTp9XFgAAANgxrORtVI9N8rEkt66qc6rqCUmOSLJbkhPGW6S+aiy7R1UdP456wyQfqapTk3wyybu6+z0rVU8AAABg+nZeqQl398Fzer9mibLnJnnA2H1mktutVL0AAACA7c9a3oUEAAAAYFkEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJi8ZQUYVfX+5fQDAAAAWAk7b2pgVV09yTWT7F5V10tS46BrJ9ljhesGAAAAkGQzAUaS30nytAxhxUm5NMD4fpJXrGC9AAAAAC6xyQCju1+W5GVV9fvd/Q+rVCcAAACAy9hcC4wkSXf/Q1X9RpK9Zsfp7tetUL0AAAAALrGsAKOqjklyyySnJLl47N1JBBgAAADAiltWgJFkfZJ9urtXsjIAAAAA8yzrNqpJTk9yo5WsCAAAAMBSltsCY/ckn62qTyb56ULP7n7IitQKAAAAYMZyA4zDV7ISAAAAAJuy3LuQfHClKwIAAACwlOXeheQHGe46kiRXTbJLkh9297VXqmIAAAAAC5bbAmO32ddV9bAk+61IjQAAAAAWWe5dSC6ju9+R5F7buC4AAAAAcy33FJJHzLy8SpL1ufSUEgAAAIAVtdy7kDx4pvuiJGcleeg2rw0AAADAHMu9Bsb/XumKAAAAACxlWdfAqKqbVtXbq+q8qvpWVb21qm660pUDAAAASJZ/Ec9/SXJckj2S3CTJO8d+AAAAACtuuQHGuu7+l+6+aHwclWTdCtYLAAAA4BLLDTDOr6rHVtVO4+OxSb69khUDAAAAWLDcAOO3kjwqyTeTfCPJI5O4sCcAAACwKpZ7G9XnJzmku7+TJFV1/SR/lyHYAAAAAFhRy22BcduF8CJJuvuCJL+2MlUCAAAAuKzlBhhXqarrLbwYW2Ast/UGAAAAwBWy3ADjxUk+WlXPr6rnJflokhdtbqSqem1VnVdVp8/0u35VnVBVXxqfr7fEuIeMZb5UVYcss54AAADAldCyAozufl2S30zyrSQbkzyiu49ZxqhHJTlgUb9nJHl/d++d5P3j68sYW3g8J8mvJ9kvyXOWCjoAAACAK79lnwbS3Z9N8tktmXh3f6iq9lrU+6FJ9h+7j05yYpI/XVTm/klOGK+1kao6IUMQcuyWzB8AAAC4cljuKSTb0g27+xtJMj7/wpwyN0ly9szrc8Z+l1NVh1XVhqrasHHjxm1eWQAAAGDtrUWAsRw1p1/PK9jdR3b3+u5ev27duhWuFgAAALAW1iLA+FZV3ThJxufz5pQ5J8meM69vmuTcVagbAAAAMEFrEWAcl2ThriKHJPn3OWXem+R+VXW98eKd9xv7AQAAADugFQ0wqurYJB9LcuuqOqeqnpDkhUnuW1VfSnLf8XWqan1VvTpJxot3Pj/Jp8bH8xYu6AkAAADseJZ9F5Kt0d0HLzHo3nPKbkjyxJnXr03y2hWqGgAAALAdmepFPAEAAAAuIcAAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJm/nta4ArIUDH/7cta4Cc7z77c9Z6yoAAAATpQUGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTt+oBRlXduqpOmXl8v6qetqjM/lX1vZkyz17tegIAAADTsfNqz7C7v5Bk3ySpqp2SfD3J2+cU/XB3P2g16wYAAABM01qfQnLvJF/p7q+ucT0AAACACVvrAOOgJMcuMezOVXVqVb27qn5lqQlU1WFVtaGqNmzcuHFlagkAAACsqTULMKrqqkkekuRf5ww+OcnNu/t2Sf4hyTuWmk53H9nd67t7/bp161amsgAAAMCaWssWGAcmObm7v7V4QHd/v7svHLuPT7JLVe2+2hUEAAAApmEtA4yDs8TpI1V1o6qqsXu/DPX89irWDQAAAJiQVb8LSZJU1TWT3DfJ78z0e1KSdPerkjwyye9W1UVJfpzkoO7utagrAAAAsPbWJMDo7h8lucGifq+a6T4iyRGrXS8AAABgmtb6LiQAAAAAmyXAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJW7MAo6rOqqrPVNUpVbVhzvCqqpdX1Zer6rSquv1a1BMAAABYezuv8fzv2d3nLzHswCR7j49fT/KP4zMAAACwg5nyKSQPTfK6Hnw8yXWr6sZrXSkAAABg9a1lgNFJ3ldVJ1XVYXOG3yTJ2TOvzxn7XUZVHVZVG6pqw8aNG1eoqgAAAMBaWssA4y7dffsMp4o8uaruvmh4zRmnL9ej+8juXt/d69etW7cS9QQAAADW2JoFGN197vh8XpK3J9lvUZFzkuw58/qmSc5dndoBAAAAU7ImAUZVXauqdlvoTnK/JKcvKnZcksePdyO5U5Lvdfc3VrmqAAAAwASs1V1Ibpjk7VW1UIc3dvd7qupJSdLdr0pyfJIHJPlykh8l+d9rVFcAAABgja1JgNHdZya53Zz+r5rp7iRPXs16AQAAANM05duoAgAAACQRYAAAAADbAQEGAAAAMHkCDAAAAGDyBBgAAADA5Awf1voAABavSURBVAkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJk+AAQAAAEyeAAMAAACYPAEGAAAAMHkCDAAAAGDyBBgAAADA5AkwAAAAgMkTYAAAAACTJ8AAAAAAJm/VA4yq2rOq/rOqPldVZ1TVU+eU2b+qvldVp4yPZ692PQEAAIDp2HkN5nlRkj/q7pOrarckJ1XVCd392UXlPtzdD1qD+gEAAAATs+otMLr7G9198tj9gySfS3KT1a4HAAAAsP1Y02tgVNVeSX4tySfmDL5zVZ1aVe+uql9Z1YoBAAAAk7IWp5AkSapq1yRvTfK07v7+osEnJ7l5d19YVQ9I8o4key8xncOSHJYkN7vZzVawxgAAAMBaWZMWGFW1S4bw4g3d/bbFw7v7+9194dh9fJJdqmr3edPq7iO7e313r1+3bt2K1hsAAABYG2txF5JK8pokn+vulyxR5kZjuVTVfhnq+e3VqyUAAAAwJWtxCsldkjwuyWeq6pSx358nuVmSdPerkjwyye9W1UVJfpzkoO7uNagrAAAAMAGrHmB090eS1GbKHJHkiNWpEQAAADB1a3oXEgAAAIDlEGAAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZPgAEAAABMngADAAAAmDwBBgAAADB5AgwAAABg8gQYAAAAwOQJMAAAAIDJE2AAAAAAkyfAAAAAACZv57WuAMBqutvvPH+tq8AcH/6nv1jxeaz/s+et+DzYMhte8OxVmc/tXvqcVZkPy3fqHz53VeZzvzf92arMh+V730EvWJX5POPEJ63KfFi+F+7/qhWfx1s+fq8Vnwdb7lF3+sA2m5YWGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATJ4AAwAAAJg8AQYAAAAweQIMAAAAYPIEGAAAAMDkCTAAAACAyRNgAAAAAJMnwAAAAAAmT4ABAAAATN6aBBhVdUBVfaGqvlxVz5gz/GpV9eZx+Ceqaq/VryUAAAAwFaseYFTVTklekeTAJPskObiq9llU7AlJvtPdt0ry0iR/s7q1BAAAAKZkLVpg7Jfky919Znf/vyRvSvLQRWUemuTosfvfkty7qmoV6wgAAABMSHX36s6w6pFJDujuJ46vH5fk17v7KTNlTh/LnDO+/spY5vw50zssyWHjy1sn+cIKv4Wp2j3J5ZYPOwTrfsdl3e+4rPsdl3W/Y7Led1zW/Y5rR1/3N+/udYt77rwGFZnXkmJxirKcMkPP7iOTHHlFK7W9q6oN3b1+revB6rPud1zW/Y7Lut9xWfc7Jut9x2Xd77is+/nW4hSSc5LsOfP6pknOXapMVe2c5DpJLliV2gEAAACTsxYBxqeS7F1Vt6iqqyY5KMlxi8ocl+SQsfuRST7Qq32uCwAAADAZq34KSXdfVFVPSfLeJDsleW13n1FVz0uyobuPS/KaJMdU1ZcztLw4aLXruR3a4U+j2YFZ9zsu637HZd3vuKz7HZP1vuOy7ndc1v0cq34RTwAAAIAttRankAAAAABsEQEGAAAAMHkCjAmrqgu3sPz+VfUfY/dDquoZK1MzZlVVV9WLZ14/vaoO34bTf3JVnTLzOH2c5y9v5fS2aLvaxHT2qqrTt8W0rgyq6uJx/ZxaVSdX1W+swDwu+YxvwTgnVtUW34Krqo6qqkdu6XhcVlU9s6rOqKrTxu3j15co97yqus+c/ttkPWztdsC2U1U3qqo3VdVXquqzVXV8Vf3SCs5vm+zrt0fzvp+q6vCqevpmxltfVS8fu/ffmv14VZ1VVbsvMezXxu/v+2/pdDc37Zkyh1bVxkW/G/bZgnk8qaoev4X12qpldWU183vg9Kr616q65mbKX+6zWlV7VNW/bWKc61bV722L+nJ5U9yHVNVvVdVnxt8Tp1fVQ8f+h1bVHsuY7rLKbQ9W/SKerI7xYqiL7+7CyvhpkkdU1Qu6+/xtPfHufkWSVyy8rqq/TnJKd39uW8+LK+TH3b1vkow/Tl+Q5B5rWyXWUlXdOcmDkty+u386/iC56pxyO3X3s1e9gqyaqqokb09ydHcfNPbbN8kNk3xxLevGpbp7Q5IN48v9k1yY5KPbcBYHJ/nI+PzexQPH7aS6++dXcD5v7u6nbM2I3f2qef2raufuvmiJ0fbPtl9W27PZ3wNvSPKkJC/Zkgl097kZ7sS4lOsm+b0kr9zaSrLtrdQ+pKpumuSZGX5PfK+qdk2ybhx8aJLTk5y7mckst9zkaYGxHRgTvBOr6t+q6vNV9YbxSy5VdcDY7yNJHjEzzqFVdcTY/eCq+kRVfbqq/m9V3XCN3sqV1UUZrhL8h4sHVNW6qnprVX1qfNxl7P+ZMT2vqvr2wr8dVXXMvH9hZ6Z39ySPyvCllaraqar+dpz2aVX1O2P/Xavq/TW0BPjMQkq7aFpzy4yp8+eq6p9r+Of4fVV1jXHYHWpoYfCxJE++gsvtyuzaSb6TbPVyvuO4Pj82rt/LtXSpqv2q6qPj5/qjVXXrsf81aviX97SqenOSa8yMc79xmieP/wrtOvZ/YQ3/CJ9WVX83M5u7j9M+s7TG2Bo3TnJ+d/80Sbr7/PFH6cI/LM8e993/s7agpcXWbFMz416lqo6uqr8cX/9jVW0Yyz93W755LuOeSX42e3DY3ack+fRW7B9+e9znnzp+v1xz7H+L8fP9qap6/sJ8lvN9sKOp4TfV31TVJ6vqi1V1t7H//lX1H1W1V4aDzj+s4Z/0u9XS3+c3GNfPp6vqn5LUEvOsDAekhya5X1Vdfey/sK5fmeTkJHtu5nP5x2O9P1lVt9qC97x/VX2wqt4yvucXVtVjxul8pqpuOZa75F/mcTn9dVV9MMlTa87vyS1cVveoS1uFfLqqdltu/bdjH05yqySpqndU1Unjej1sccGq2n38DD+wZloAVNWvjOvplBq+p/dO8sIktxz7/e0V+V5gy63BPuQXkvwgQyCS7r6wu/+7ht8N65O8YZzPNWr4bfGpGlppHFmDeeXuMO4TTqqq91bVjcf6/EFd+pvwTSu7JLdSd3tM9JHkwvF5/yTfS3LTDKHTx5LcNcnVk5ydZO8MG/tbkvzHOM6hSY4Yu6+XS+8488QkL17r93ZlemTYmVw7yVlJrpPk6UkOH4e9Mcldx+6bJfnc2P2qJA9M8qtJPpXkn8f+X0qy6xLzuW6SryS5y0y/w5I8a+y+WobU9xYZWldde+y/e5Ivz2wDC9vV3DJJ9soQyuw7DntLkseO3aclucfY/bdJTl/r5T+VR5KLk5yS5PPj5/UOV2A5n57kN8buFy4s53FfsPAZv3aSncfu+yR569j9fzLcnjpJbjvOY/047w8ludY47E+TPDvJ9ZN8YWb7uO74fFSSf82wz9knyZfXehlvb48ku47bxBcz/Et2j5lhZyX5k5nXRyV55JxpXK7/Vm5TJya5U5JjkzxzZlrXH593Gsvcdq2X25XxkeQPkrx0Tv+tWZc3mBn/L5P8/th9XJLHj91Pzmb29Wu9TFZ4ee+VRd9PSQ5P8vSx+8SMv4WSPCDJ/x2798+l+9hLyo+vl/o+f3mSZ4/dD0zSSXafU6e7Jnn/zLQeMVPXnye500zZuZ/Lcb/xzLH78Qt1XTSfQ5NszLDvWXhcY3xv380QrF4tydeTPHcc56lJ/n6J5fTKmWnP/T25BcvqnRl/w2TYP+681tvKCm1/s5+9f0/yu4vW6zUyfM/fYKF8htZYn0hy38XbcJJ/SPKYsfuq4/iXDJ+Z1xbtSzw2uQ4vs3zHfos/G6u2D8mwL3hvkq8l+ZckD54ZdmKS9TOvrz/TfcxC2dlySXbJ0DJk3fj60bn0t+O5Sa42dl93rdfFvIdTSLYfn+zuc5Kkqk7J8MG6MMl/d/eXxv6vz3BAu9hNk7x5TNaumuS/V6XGO5Du/n5VvS7Dj9Qfzwy6T5J9hj9ekiTXHv9x+HCSuyf5apJ/THJYVd0kyQXdvdR5y/+Y5PXd/V8z/e6X5LZ16T+318kQaJ2T5K9raLHx8yQ3yfDl+M2ZcWuJMsmwXZ0ydp+UZK+quk6GHdkHx/7HJDlwM4tmRzLbZPTOSV5XVb+aLV/O102yW3cvNDl8Y4bTEBa7TpKjx39iOsOXUTJsVy9Pku4+rapOG/vfKUMQ8V/j9njVDGHo95P8JMmrq+pdSWavsfGOHpoyf7a03Npi3X1hVd0hyd0y/AP/5qp6RncfNRZ581ZOeou2qZnx/inJW7r7r2b6PWr8J3DnDAc2+2QIKlkdW7Muf7WGFjTXzXAQuHAqwl2S/ObYfUySv9nMPGa/D65sehn93zY+L/6cLGWp7/O7Z2wB293vqqrvLDH+wUkW/s18U5LHzdThq9398Zmym/pcHjvz/NIl5nW5U0jGen+qu78xvv5KkveNgz+TYR81d1oz3cv9PbnUsvqvJC+p4bSKty38rr0Susb4Wz0Zfu+9Zuz+g6p6+Ni9Z4bfa9/O8P39/iRPnvmNNetjSZ5Zw2kEb+vuL80s2wVb+73AfJPah3T3xVV1QJI7Jrl3kpdW1R26+/A587lnVf1Jkmtm+JPqjAzh4axbZ/gT9YSxPjsl+cY47LQMLTXekeQdy3hfq06Asf346Uz3xbl03S31AZv1D0le0t3HVdX+GRJBtr2/z9D8819m+l0lyZ27ezbUSFV9KMM/ZDfLcE7bwzM0Lf3wvAlX1SEZdo6PWzwow79v711U/tAM58bdobt/VlVnZWixM+sxmyizeHu7xjiv5WxvO7zu/lgN1ztYlyGZ39LlvBzPT/Kf3f3wsaniibNVmFO+kpzQ3QdfbkDVfhm+EA9K8pQk95pTv+XWixndfXGGdXNiVX0mySEZWlUkyQ+3crJb+tld8NEMP2xe3N0/qapbZGgxdsfu/k5VHZXL7yfYNs7I/PPZt2ZdHpXkYd196riv33+m3LzP/qbmcWX17QytBWZdP5c94F5YvrO/qTZlqe/zZDPfjVW1U4Zw6SFV9cwM+9Mb1KWnUPxwpuzmPpe9RPdyzG5TP595/fMsvQxm91PL/T05d1kleeEYlD8gycer6j7d/fktqP/24pI/NBaMy+s+GZbLj6rqxFy6Xi/KcBB8/ySXCzC6+41V9YkM/86/t6qemOTMRcW29nuB+Sa1D0mSHppEfDLJJ6vqhAzHG4cvmtbVM7T4XN/dZ9dwU4F5+/tKckZ333nOsAdmCFUekuQvqupXeunr36wJ18DYvn0+yS1qPG8xQ7o/z3UyNBVMhh/PrIDuviBD07wnzPR+X4YDwiSXXLQt3X12hiZ+e3f3mRku6vX0zAkwquoXk/xVhuaDi3cg703yu1W1y1j2l6rqWhnW+Xnjl9g9k9x8TpWXU2b2/X03yfeq6q5jr8dsqvyOrKpukyHN/na2fDl/J8kPqupOY6+Dlig6+7k+dKb/hzKum7EFyG3H/h9Pcpcaz5muqmuO28uuSa7T3ccneVqSy/zoYutV1a3HFjIL9s3Q6uqK2qJtasZrkhyf5F+raucMpyH9MMPn+obRomolfSDJ1arqtxd6VNUdM6y7LV2XuyX5xrjfn90P/1cu3V/M9t/a7WW7NbZk/EZV3TtJqur6SQ7I8F27XD/IsKwXzP0+z2X3uQfm8gc9yXDgemp379nde3X3zZO8NcnD5pTd3Ofy0TPPH9uC97MtLPV7clnLqqpu2d2f6e6/yXDK621WtrqTcp0k3xnDi9tkaBW5oJP8VpLb1Jw7CI6/A8/s7pdnOFXstrn8Mt/hPucraWr7kBruSnP7mV6zvydm57MQVpw//r6bDc5ny30hybqxxXCqapcarrVylSR7dvd/JvmTXNrSb1IEGNux7v5JhlNG3lXDheCW+mF8eIYfrB9Oss3vksFlvDhDMLHgD5Ksr+FCOJ/NcEGfBZ/IpVef/3CG5n7zdox/muRaSd5Wl70t2t2SvDrJZ5OcXMPFnv4pQwr8hnG+GzLsFOf9w7GcMov97ySvqOEinov/WdnRXWNh3WRocnvI+O/71iznJyQ5clzOleGaGou9KMkLquq/MoQlC/4xya41nDryJxnS+nT3xgxBx7HjsI9n+PG4W5L/GPt9MHMuRstW2zXDaT6fHZfvPtm6FnD/VFXnjI+PZeu2qSRJd78kQ0uxYzI0G/90htYBr81wAMwKGP85e3iS+9ZwG9UzMmwLx2fL1+VfZPj+OGFR+acmeXJVfSrDwcyCrd5etnOPT/KscZ/8gQzXe/jKFoz/ziQPn/m+Xer7/LkZLnh8cobTOr82Z1oHZ7gLzay3Jvlfiwt296nZ9OfyauO/8U/N0vvrRy/6vbCtbnF6eOb/nlzusnpaDRcWPDXDb4h3b6N6bQ/ek2Tn8bvg+Rm+gy8x/l44KEMrucW3R310ktPHbfk2SV7X3d/OcEro6VX1t9lxP+craUr7kF2S/F0NN244JcM28dRx2FFJXjX2/2mSf87w/f6ODNfZy5xyO2UIN/5m/DyekuQ3xv6vr6HF6KczXLvpu1vwnlfFwoV4AJiIqtp14Voo478xN+7up25mNAAAuFJzDQyA6XlgVf1Zhn30V3PZU0QAAGCHpAUGAAAAMHmugQEAAABMngADAAAAmDwBBgAAADB5AgwAYJurqhtV1ZvG24Z+tqqOr6pf2obT339Tt4esqoeMd/EBAK4kXMQTANimqqqSfDTJ0d39qrHfvkl26+4Pb6N5HJ7kwu7+uznDdu7ui7bFfACA6RBgAADbVFXdK8nh3X33Rf0ryYuSHJikk/xld7+5qvZP8vTuftBY7ogkG7r7qKo6K8nRSR6cZJck/zPJT5J8PMnFSTYm+f0kT0hyQZJfS3Jyks8kWf//27ufFx/iOI7jzxcKtbhwUntRQspGe1AicRcXV4US0h7kb+Dix0HtPyCF9uIgDopsCZusuLhQDpRSNkXZ3g4zaml3fdW33UnPR02fek/zmc/MaXrNZz5TVaeTrANGgcF2KCNVNZ5kD3ClrRWwu6qm+n0/JElSfyxb7AFIkqT/zlZgYpb6IWAI2AasBZ4medhDf5+qanuSkzRBx7Eko8yYgZHkKLAR2F9V00mOzDj+CnCpqh4lGQTuApuBs8CpNswYoAlGJElSRxlgSJKkhbILuF5V08DHJA+AYeDLX44ba9sJmhBkLjfbvv+0H9jSTAABYHWSVcA4cDHJNWCsqt73eB2SJGkRuIinJEnqt1fAjlnqmaUG8IPfn0lW/LH/e9tOM//Ll69z1JcAO6tqqN3WV9VUVZ0HjgErgcdJNs3TtyRJWmQGGJIkqd/uA8uTHP9VSDIMfAYOJ1narkuxG3gCvKOZIbE8yRpgXw/nmAJW9Tiee8DpGWMZatsNVfWyqi4AzwADDEmSOsxPSCRJUl9VVSU5CFxuf2X6DXgLjAADwAuaRTPPVdUHgCQ3gEngDfC8h9PcBm4lOUCziOd8zgBXk0zSPPs8BE4AI0n20szseA3c+ZfrlCRJC8u/kEiSJEmSpM7zExJJkiRJktR5BhiSJEmSJKnzDDAkSZIkSVLnGWBIkiRJkqTOM8CQJEmSJEmdZ4AhSZIkSZI6zwBDkiRJkiR13k9YVNceehSV9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in data['ethnicity'].unique():\n",
    "    plot_e(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,6))\n",
    "sns.countplot(x='austim',data=data,hue='ethnicity',palette='rainbow',ax=ax[0])\n",
    "ax[0].set_title('Positive ASD Adult relatives with Autism distribution for different ethnicities')\n",
    "ax[0].set_xlabel('Adult Relatives with ASD')\n",
    "#sns.countplot(x='Family_mem_with_ASD',data=data2,hue='Ethnicity',palette='rainbow',ax=ax[1])\n",
    "#ax[1].set_title('Positive ASD Toddler relatives with Autism distribution for different ethnicities')\n",
    "#ax[1].set_xlabel('Toddler Relatives with ASD')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'Brazil', 'Spain', 'Egypt', 'New Zealand',\n",
       "       'Bahamas', 'Burundi', 'Austria', 'Argentina', 'Jordan', 'Ireland',\n",
       "       'United Arab Emirates', 'Afghanistan', 'Lebanon', 'United Kingdom',\n",
       "       'South Africa', 'Italy', 'Pakistan', 'Bangladesh', 'Chile',\n",
       "       'France', 'China', 'Australia', 'Canada', 'Saudi Arabia',\n",
       "       'Netherlands', 'Romania', 'Sweden', 'Tonga', 'Oman', 'India',\n",
       "       'Philippines', 'Sri Lanka', 'Sierra Leone', 'Ethiopia', 'Viet Nam',\n",
       "       'Iran', 'Costa Rica', 'Germany', 'Mexico', 'Russia', 'Armenia',\n",
       "       'Iceland', 'Nicaragua', 'Hong Kong', 'Japan', 'Ukraine',\n",
       "       'Kazakhstan', 'AmericanSamoa', 'Uruguay', 'Serbia', 'Portugal',\n",
       "       'Malaysia', 'Ecuador', 'Niger', 'Belgium', 'Bolivia', 'Aruba',\n",
       "       'Finland', 'Turkey', 'Nepal', 'Indonesia', 'Angola', 'Azerbaijan',\n",
       "       'Iraq', 'Czech Republic', 'Cyprus'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['contry_of_res'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White-European', 'Latino', 'Others', 'Black', 'Asian',\n",
       "       'Middle Eastern ', 'Pasifika', 'South Asian', 'Hispanic',\n",
       "       'Turkish', 'others'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Self', 'Parent', 'Health care professional', 'Relative', 'Others'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['relation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['26', '24', '27', '35', '40', '36', '17', '64', '29', '33', '18',\n",
       "       '31', '30', '34', '38', '42', '43', '48', '37', '55', '50', '53',\n",
       "       '20', '28', '21', '383', '47', '32', '44', '19', '58', '45', '22',\n",
       "       '39', '25', '23', '54', '60', '41', '46', '56', '61', '59', '52',\n",
       "       '49', '51'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data sets//datasets_38367_58429_Toddler Autism dataset July 2018.csv',na_values = '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop('Case_No',inplace = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score Sex  \\\n",
       "0   0   0   0   0   0   0   1   1   0    1        28               3   f   \n",
       "1   1   1   0   0   0   1   1   0   0    0        36               4   m   \n",
       "2   1   0   0   0   0   0   1   1   0    1        36               4   m   \n",
       "3   1   1   1   1   1   1   1   1   1    1        24              10   m   \n",
       "4   1   1   0   1   1   1   1   1   1    1        20               9   f   \n",
       "\n",
       "        Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0  middle eastern      yes                  no          family member   \n",
       "1  White European      yes                  no          family member   \n",
       "2  middle eastern      yes                  no          family member   \n",
       "3        Hispanic       no                  no          family member   \n",
       "4  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'no'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Jaundice'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['family member', 'Health Care Professional',\n",
       "       'Health care professional', 'Self', 'Others'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Who completed the test'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Family_mem_with_ASD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1054.000000\n",
       "mean       27.867173\n",
       "std         7.980354\n",
       "min        12.000000\n",
       "25%        23.000000\n",
       "50%        30.000000\n",
       "75%        36.000000\n",
       "max        36.000000\n",
       "Name: Age_Mons, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Age_Mons'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Age_Mons'] = data1['Age_Mons']//12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Age_Mons'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score Sex  \\\n",
       "0   0   0   0   0   0   0   1   1   0    1         2               3   f   \n",
       "1   1   1   0   0   0   1   1   0   0    0         3               4   m   \n",
       "2   1   0   0   0   0   0   1   1   0    1         3               4   m   \n",
       "3   1   1   1   1   1   1   1   1   1    1         2              10   m   \n",
       "4   1   1   0   1   1   1   1   1   1    1         1               9   f   \n",
       "\n",
       "        Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0  middle eastern      yes                  no          family member   \n",
       "1  White European      yes                  no          family member   \n",
       "2  middle eastern      yes                  no          family member   \n",
       "3        Hispanic       no                  no          family member   \n",
       "4  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "data1 = pd.DataFrame(imp.fit_transform(data1),columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 Age_Mons Qchat-10-Score Sex       Ethnicity  \\\n",
       "0  0  0  0  0  0  0  1  1  0   1        2              3   f  middle eastern   \n",
       "1  1  1  0  0  0  1  1  0  0   0        3              4   m  White European   \n",
       "2  1  0  0  0  0  0  1  1  0   1        3              4   m  middle eastern   \n",
       "3  1  1  1  1  1  1  1  1  1   1        2             10   m        Hispanic   \n",
       "4  1  1  0  1  1  1  1  1  1   1        1              9   f  White European   \n",
       "\n",
       "  Jaundice Family_mem_with_ASD Who completed the test Class/ASD Traits   \n",
       "0      yes                  no          family member                No  \n",
       "1      yes                  no          family member               Yes  \n",
       "2      yes                  no          family member               Yes  \n",
       "3       no                  no          family member               Yes  \n",
       "4       no                 yes          family member               Yes  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Class/ASD Traits '].replace(['No', 'Yes'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Class/ASD Traits '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Sex'].replace(['f', 'm'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Jaundice'].replace(['yes', 'no'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Family_mem_with_ASD'].replace(['yes', 'no'],[0,1],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['family member', 'Health Care Professional',\n",
       "       'Health care professional', 'Self', 'Others'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Who completed the test'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1, 3, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "data1['Who completed the test']= label_encoder.fit_transform(data1['Who completed the test']) \n",
    "data1['Who completed the test'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1                        object\n",
       "A2                        object\n",
       "A3                        object\n",
       "A4                        object\n",
       "A5                        object\n",
       "A6                        object\n",
       "A7                        object\n",
       "A8                        object\n",
       "A9                        object\n",
       "A10                       object\n",
       "Age_Mons                  object\n",
       "Qchat-10-Score            object\n",
       "Sex                        int64\n",
       "Ethnicity                 object\n",
       "Jaundice                   int64\n",
       "Family_mem_with_ASD        int64\n",
       "Who completed the test     int32\n",
       "Class/ASD Traits           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons',\n",
       "       'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
       "       'Who completed the test', 'Class/ASD Traits '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['middle eastern', 'White European', 'Hispanic', 'black', 'asian',\n",
       "       'south asian', 'Native Indian', 'Others', 'Latino', 'mixed',\n",
       "       'Pacifica'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5,  0,  7,  6, 10,  2,  3,  1,  9,  4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Ethnicity']= label_encoder.fit_transform(data1['Ethnicity']) \n",
    "data1['Ethnicity'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1                        object\n",
       "A2                        object\n",
       "A3                        object\n",
       "A4                        object\n",
       "A5                        object\n",
       "A6                        object\n",
       "A7                        object\n",
       "A8                        object\n",
       "A9                        object\n",
       "A10                       object\n",
       "Age_Mons                  object\n",
       "Qchat-10-Score            object\n",
       "Sex                        int64\n",
       "Ethnicity                  int32\n",
       "Jaundice                   int64\n",
       "Family_mem_with_ASD        int64\n",
       "Who completed the test     int32\n",
       "Class/ASD Traits           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    data1.iloc[:,i] = data1.iloc[:,i].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1                         int32\n",
       "A2                         int32\n",
       "A3                         int32\n",
       "A4                         int32\n",
       "A5                         int32\n",
       "A6                         int32\n",
       "A7                         int32\n",
       "A8                         int32\n",
       "A9                         int32\n",
       "A10                        int32\n",
       "Age_Mons                   int32\n",
       "Qchat-10-Score            object\n",
       "Sex                        int64\n",
       "Ethnicity                  int32\n",
       "Jaundice                   int64\n",
       "Family_mem_with_ASD        int64\n",
       "Who completed the test     int32\n",
       "Class/ASD Traits           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Qchat-10-Score'] = data1['Qchat-10-Score'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4, 10,  9,  8,  5,  6,  2,  0,  7,  1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Qchat-10-Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1                        int32\n",
       "A2                        int32\n",
       "A3                        int32\n",
       "A4                        int32\n",
       "A5                        int32\n",
       "A6                        int32\n",
       "A7                        int32\n",
       "A8                        int32\n",
       "A9                        int32\n",
       "A10                       int32\n",
       "Age_Mons                  int32\n",
       "Qchat-10-Score            int32\n",
       "Sex                       int64\n",
       "Ethnicity                 int32\n",
       "Jaundice                  int64\n",
       "Family_mem_with_ASD       int64\n",
       "Who completed the test    int32\n",
       "Class/ASD Traits          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data1.iloc[:,0:17]\n",
    "y1 = data1.iloc[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  Sex  \\\n",
       "0      0   0   0   0   0   0   1   1   0    1         2               3    0   \n",
       "1      1   1   0   0   0   1   1   0   0    0         3               4    1   \n",
       "2      1   0   0   0   0   0   1   1   0    1         3               4    1   \n",
       "3      1   1   1   1   1   1   1   1   1    1         2              10    1   \n",
       "4      1   1   0   1   1   1   1   1   1    1         1               9    0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...       ...             ...  ...   \n",
       "1049   0   0   0   0   0   0   0   0   0    1         2               1    0   \n",
       "1050   0   0   1   1   1   0   1   0   1    0         1               5    1   \n",
       "1051   1   0   1   1   1   1   1   1   1    1         1               9    1   \n",
       "1052   1   0   0   0   0   0   0   1   0    1         1               3    1   \n",
       "1053   1   1   0   0   1   1   0   1   1    0         2               6    1   \n",
       "\n",
       "      Ethnicity  Jaundice  Family_mem_with_ASD  Who completed the test  \n",
       "0             8         0                    1                       4  \n",
       "1             5         0                    1                       4  \n",
       "2             8         0                    1                       4  \n",
       "3             0         1                    1                       4  \n",
       "4             5         1                    0                       4  \n",
       "...         ...       ...                  ...                     ...  \n",
       "1049          5         1                    0                       4  \n",
       "1050          7         0                    1                       4  \n",
       "1051          8         0                    1                       4  \n",
       "1052          5         1                    0                       4  \n",
       "1053          6         0                    0                       4  \n",
       "\n",
       "[1054 rows x 17 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1049    0\n",
       "1050    1\n",
       "1051    1\n",
       "1052    0\n",
       "1053    1\n",
       "Name: Class/ASD Traits , Length: 1054, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 13, 56, 22, 43,  9, 14,  7,  3, 36, 33, 62,  0, 38, 63, 55, 34,\n",
       "       47, 10, 16, 25, 17,  6, 15, 52, 42, 50, 58, 59, 46, 29, 48, 57, 54,\n",
       "       23, 66, 31, 18, 26, 40, 51,  4, 28, 44, 27, 35, 61, 37,  1, 65, 53,\n",
       "       49, 39, 21, 45, 11, 12,  5, 24, 60, 41, 30,  2,  8, 32, 20, 19])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "data['contry_of_res']= label_encoder.fit_transform(data['contry_of_res']) \n",
    "data['contry_of_res'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity']  = label_encoder.fit_transform(data['ethnicity']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relation'] = label_encoder.fit_transform(data['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  3,  5,  1,  0,  4,  6,  7,  2,  8, 10])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 0, 3, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['relation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('contry_of_res',inplace = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 18)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score     object\n",
       "A2_Score     object\n",
       "A3_Score     object\n",
       "A4_Score     object\n",
       "A5_Score     object\n",
       "A6_Score     object\n",
       "A7_Score     object\n",
       "A8_Score     object\n",
       "A9_Score     object\n",
       "A10_Score    object\n",
       "age          object\n",
       "result       object\n",
       "gender        int64\n",
       "ethnicity     int32\n",
       "jundice       int64\n",
       "austim        int64\n",
       "relation      int32\n",
       "Class/ASD     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    data.iloc[:,i] = data.iloc[:,i].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score      int32\n",
       "A2_Score      int32\n",
       "A3_Score      int32\n",
       "A4_Score      int32\n",
       "A5_Score      int32\n",
       "A6_Score      int32\n",
       "A7_Score      int32\n",
       "A8_Score      int32\n",
       "A9_Score      int32\n",
       "A10_Score     int32\n",
       "age           int32\n",
       "result       object\n",
       "gender        int64\n",
       "ethnicity     int32\n",
       "jundice       int64\n",
       "austim        int64\n",
       "relation      int32\n",
       "Class/ASD     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['result'] = data['result'].astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score     int32\n",
       "A2_Score     int32\n",
       "A3_Score     int32\n",
       "A4_Score     int32\n",
       "A5_Score     int32\n",
       "A6_Score     int32\n",
       "A7_Score     int32\n",
       "A8_Score     int32\n",
       "A9_Score     int32\n",
       "A10_Score    int32\n",
       "age          int32\n",
       "result       int32\n",
       "gender       int64\n",
       "ethnicity    int32\n",
       "jundice      int64\n",
       "austim       int64\n",
       "relation     int32\n",
       "Class/ASD    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>result</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "0           1         1         1         1         0         0         1   \n",
       "1           1         1         0         1         0         0         0   \n",
       "2           1         1         0         1         1         0         1   \n",
       "3           1         1         0         1         0         0         1   \n",
       "4           1         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "699         0         1         0         1         1         0         1   \n",
       "700         1         0         0         0         0         0         0   \n",
       "701         1         0         1         1         1         0         1   \n",
       "702         1         0         0         1         1         0         1   \n",
       "703         1         0         1         1         1         0         1   \n",
       "\n",
       "     A8_Score  A9_Score  A10_Score  age  result  gender  ethnicity  jundice  \\\n",
       "0           1         0          0   26       6       0          9        0   \n",
       "1           1         0          1   24       5       1          3        0   \n",
       "2           1         1          1   27       8       1          3        1   \n",
       "3           1         0          1   35       6       0          9        0   \n",
       "4           1         0          0   40       2       0          9        0   \n",
       "..        ...       ...        ...  ...     ...     ...        ...      ...   \n",
       "699         1         1          1   25       7       0          9        0   \n",
       "700         1         0          1   34       3       1          2        0   \n",
       "701         1         0          1   24       7       0          9        0   \n",
       "702         0         1          1   35       6       1          7        0   \n",
       "703         1         1          1   26       8       0          9        0   \n",
       "\n",
       "     austim  relation  Class/ASD  \n",
       "0         0         4          0  \n",
       "1         1         4          0  \n",
       "2         1         2          1  \n",
       "3         1         4          0  \n",
       "4         0         4          0  \n",
       "..      ...       ...        ...  \n",
       "699       0         4          1  \n",
       "700       0         2          0  \n",
       "701       0         4          1  \n",
       "702       0         4          0  \n",
       "703       0         4          1  \n",
       "\n",
       "[704 rows x 18 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>result</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1_Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.074096</td>\n",
       "      <td>0.127814</td>\n",
       "      <td>0.169369</td>\n",
       "      <td>0.110199</td>\n",
       "      <td>0.217538</td>\n",
       "      <td>0.147640</td>\n",
       "      <td>0.145452</td>\n",
       "      <td>0.118413</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.397454</td>\n",
       "      <td>-0.075011</td>\n",
       "      <td>0.053684</td>\n",
       "      <td>-0.019077</td>\n",
       "      <td>0.097630</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.297628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2_Score</th>\n",
       "      <td>0.011539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223921</td>\n",
       "      <td>0.158998</td>\n",
       "      <td>0.153821</td>\n",
       "      <td>0.185864</td>\n",
       "      <td>-0.041768</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>0.205421</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.392540</td>\n",
       "      <td>-0.047393</td>\n",
       "      <td>0.128518</td>\n",
       "      <td>0.112615</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>-0.047792</td>\n",
       "      <td>0.311382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3_Score</th>\n",
       "      <td>0.074096</td>\n",
       "      <td>0.223921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412722</td>\n",
       "      <td>0.264927</td>\n",
       "      <td>0.268846</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.168454</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.552356</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.110339</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.113697</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.441074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4_Score</th>\n",
       "      <td>0.127814</td>\n",
       "      <td>0.158998</td>\n",
       "      <td>0.412722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306806</td>\n",
       "      <td>0.295152</td>\n",
       "      <td>0.151236</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.327673</td>\n",
       "      <td>0.210968</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>0.586025</td>\n",
       "      <td>-0.056508</td>\n",
       "      <td>0.140787</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>0.193820</td>\n",
       "      <td>-0.013804</td>\n",
       "      <td>0.469945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5_Score</th>\n",
       "      <td>0.169369</td>\n",
       "      <td>0.153821</td>\n",
       "      <td>0.264927</td>\n",
       "      <td>0.306806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.392354</td>\n",
       "      <td>0.238589</td>\n",
       "      <td>0.102086</td>\n",
       "      <td>0.396582</td>\n",
       "      <td>0.267561</td>\n",
       "      <td>-0.025054</td>\n",
       "      <td>0.639706</td>\n",
       "      <td>-0.039688</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.034378</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>0.048976</td>\n",
       "      <td>0.537004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A6_Score</th>\n",
       "      <td>0.110199</td>\n",
       "      <td>0.185864</td>\n",
       "      <td>0.268846</td>\n",
       "      <td>0.295152</td>\n",
       "      <td>0.392354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175489</td>\n",
       "      <td>0.100123</td>\n",
       "      <td>0.479422</td>\n",
       "      <td>0.294435</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>0.630012</td>\n",
       "      <td>-0.083615</td>\n",
       "      <td>0.108745</td>\n",
       "      <td>0.078366</td>\n",
       "      <td>0.114048</td>\n",
       "      <td>-0.090688</td>\n",
       "      <td>0.592091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7_Score</th>\n",
       "      <td>0.217538</td>\n",
       "      <td>-0.041768</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>0.151236</td>\n",
       "      <td>0.238589</td>\n",
       "      <td>0.175489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085403</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>-0.026734</td>\n",
       "      <td>0.454848</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>-0.008610</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.351429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A8_Score</th>\n",
       "      <td>0.147640</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.102086</td>\n",
       "      <td>0.100123</td>\n",
       "      <td>0.085403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101733</td>\n",
       "      <td>0.100782</td>\n",
       "      <td>-0.078154</td>\n",
       "      <td>0.324020</td>\n",
       "      <td>0.064127</td>\n",
       "      <td>-0.048702</td>\n",
       "      <td>0.012101</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.051040</td>\n",
       "      <td>0.237161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9_Score</th>\n",
       "      <td>0.145452</td>\n",
       "      <td>0.205421</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.327673</td>\n",
       "      <td>0.396582</td>\n",
       "      <td>0.479422</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.101733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283340</td>\n",
       "      <td>0.054984</td>\n",
       "      <td>0.661205</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.057717</td>\n",
       "      <td>0.167644</td>\n",
       "      <td>-0.058046</td>\n",
       "      <td>0.635576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10_Score</th>\n",
       "      <td>0.118413</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>0.168454</td>\n",
       "      <td>0.210968</td>\n",
       "      <td>0.267561</td>\n",
       "      <td>0.294435</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>0.100782</td>\n",
       "      <td>0.283340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>0.537205</td>\n",
       "      <td>-0.055246</td>\n",
       "      <td>0.059843</td>\n",
       "      <td>0.052201</td>\n",
       "      <td>0.117969</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.385917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>-0.025054</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>-0.026734</td>\n",
       "      <td>-0.078154</td>\n",
       "      <td>0.054984</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>-0.051266</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>0.065387</td>\n",
       "      <td>0.095511</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>0.060054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.397454</td>\n",
       "      <td>0.392540</td>\n",
       "      <td>0.552356</td>\n",
       "      <td>0.586025</td>\n",
       "      <td>0.639706</td>\n",
       "      <td>0.630012</td>\n",
       "      <td>0.454848</td>\n",
       "      <td>0.324020</td>\n",
       "      <td>0.661205</td>\n",
       "      <td>0.537205</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>0.124213</td>\n",
       "      <td>0.094842</td>\n",
       "      <td>0.192033</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>0.821445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-0.075011</td>\n",
       "      <td>-0.047393</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>-0.056508</td>\n",
       "      <td>-0.039688</td>\n",
       "      <td>-0.083615</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.064127</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>-0.055246</td>\n",
       "      <td>-0.051266</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091333</td>\n",
       "      <td>-0.018842</td>\n",
       "      <td>-0.088477</td>\n",
       "      <td>-0.065708</td>\n",
       "      <td>-0.080378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>0.053684</td>\n",
       "      <td>0.128518</td>\n",
       "      <td>0.110339</td>\n",
       "      <td>0.140787</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.108745</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>-0.048702</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.059843</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>0.124213</td>\n",
       "      <td>-0.091333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074951</td>\n",
       "      <td>0.117392</td>\n",
       "      <td>0.093633</td>\n",
       "      <td>0.144476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jundice</th>\n",
       "      <td>-0.019077</td>\n",
       "      <td>0.112615</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>0.034378</td>\n",
       "      <td>0.078366</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>0.012101</td>\n",
       "      <td>0.057717</td>\n",
       "      <td>0.052201</td>\n",
       "      <td>0.065387</td>\n",
       "      <td>0.094842</td>\n",
       "      <td>-0.018842</td>\n",
       "      <td>0.074951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157793</td>\n",
       "      <td>-0.098007</td>\n",
       "      <td>0.102152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austim</th>\n",
       "      <td>0.097630</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.113697</td>\n",
       "      <td>0.193820</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>0.114048</td>\n",
       "      <td>-0.008610</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.167644</td>\n",
       "      <td>0.117969</td>\n",
       "      <td>0.095511</td>\n",
       "      <td>0.192033</td>\n",
       "      <td>-0.088477</td>\n",
       "      <td>0.117392</td>\n",
       "      <td>0.157793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119433</td>\n",
       "      <td>0.177415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <td>0.008398</td>\n",
       "      <td>-0.047792</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>-0.013804</td>\n",
       "      <td>0.048976</td>\n",
       "      <td>-0.090688</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.051040</td>\n",
       "      <td>-0.058046</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-0.065708</td>\n",
       "      <td>0.093633</td>\n",
       "      <td>-0.098007</td>\n",
       "      <td>-0.119433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class/ASD</th>\n",
       "      <td>0.297628</td>\n",
       "      <td>0.311382</td>\n",
       "      <td>0.441074</td>\n",
       "      <td>0.469945</td>\n",
       "      <td>0.537004</td>\n",
       "      <td>0.592091</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.237161</td>\n",
       "      <td>0.635576</td>\n",
       "      <td>0.385917</td>\n",
       "      <td>0.060054</td>\n",
       "      <td>0.821445</td>\n",
       "      <td>-0.080378</td>\n",
       "      <td>0.144476</td>\n",
       "      <td>0.102152</td>\n",
       "      <td>0.177415</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  \\\n",
       "A1_Score   1.000000  0.011539  0.074096  0.127814  0.169369  0.110199   \n",
       "A2_Score   0.011539  1.000000  0.223921  0.158998  0.153821  0.185864   \n",
       "A3_Score   0.074096  0.223921  1.000000  0.412722  0.264927  0.268846   \n",
       "A4_Score   0.127814  0.158998  0.412722  1.000000  0.306806  0.295152   \n",
       "A5_Score   0.169369  0.153821  0.264927  0.306806  1.000000  0.392354   \n",
       "A6_Score   0.110199  0.185864  0.268846  0.295152  0.392354  1.000000   \n",
       "A7_Score   0.217538 -0.041768  0.078216  0.151236  0.238589  0.175489   \n",
       "A8_Score   0.147640  0.035408  0.017771  0.008617  0.102086  0.100123   \n",
       "A9_Score   0.145452  0.205421  0.315113  0.327673  0.396582  0.479422   \n",
       "A10_Score  0.118413  0.068883  0.168454  0.210968  0.267561  0.294435   \n",
       "age        0.025379  0.020644  0.030833  0.033967 -0.025054  0.035617   \n",
       "result     0.397454  0.392540  0.552356  0.586025  0.639706  0.630012   \n",
       "gender    -0.075011 -0.047393  0.000795 -0.056508 -0.039688 -0.083615   \n",
       "ethnicity  0.053684  0.128518  0.110339  0.140787  0.009535  0.108745   \n",
       "jundice   -0.019077  0.112615  0.061760  0.064918  0.034378  0.078366   \n",
       "austim     0.097630  0.074555  0.113697  0.193820  0.090009  0.114048   \n",
       "relation   0.008398 -0.047792  0.029318 -0.013804  0.048976 -0.090688   \n",
       "Class/ASD  0.297628  0.311382  0.441074  0.469945  0.537004  0.592091   \n",
       "\n",
       "           A7_Score  A8_Score  A9_Score  A10_Score       age    result  \\\n",
       "A1_Score   0.217538  0.147640  0.145452   0.118413  0.025379  0.397454   \n",
       "A2_Score  -0.041768  0.035408  0.205421   0.068883  0.020644  0.392540   \n",
       "A3_Score   0.078216  0.017771  0.315113   0.168454  0.030833  0.552356   \n",
       "A4_Score   0.151236  0.008617  0.327673   0.210968  0.033967  0.586025   \n",
       "A5_Score   0.238589  0.102086  0.396582   0.267561 -0.025054  0.639706   \n",
       "A6_Score   0.175489  0.100123  0.479422   0.294435  0.035617  0.630012   \n",
       "A7_Score   1.000000  0.085403  0.189480   0.252107 -0.026734  0.454848   \n",
       "A8_Score   0.085403  1.000000  0.101733   0.100782 -0.078154  0.324020   \n",
       "A9_Score   0.189480  0.101733  1.000000   0.283340  0.054984  0.661205   \n",
       "A10_Score  0.252107  0.100782  0.283340   1.000000 -0.007846  0.537205   \n",
       "age       -0.026734 -0.078154  0.054984  -0.007846  1.000000  0.011561   \n",
       "result     0.454848  0.324020  0.661205   0.537205  0.011561  1.000000   \n",
       "gender     0.061900  0.064127  0.006940  -0.055246 -0.051266 -0.042231   \n",
       "ethnicity -0.002004 -0.048702  0.081052   0.059843  0.083560  0.124213   \n",
       "jundice    0.030850  0.012101  0.057717   0.052201  0.065387  0.094842   \n",
       "austim    -0.008610  0.034845  0.167644   0.117969  0.095511  0.192033   \n",
       "relation   0.032594  0.051040 -0.058046   0.027427 -0.028200 -0.000760   \n",
       "Class/ASD  0.351429  0.237161  0.635576   0.385917  0.060054  0.821445   \n",
       "\n",
       "             gender  ethnicity   jundice    austim  relation  Class/ASD  \n",
       "A1_Score  -0.075011   0.053684 -0.019077  0.097630  0.008398   0.297628  \n",
       "A2_Score  -0.047393   0.128518  0.112615  0.074555 -0.047792   0.311382  \n",
       "A3_Score   0.000795   0.110339  0.061760  0.113697  0.029318   0.441074  \n",
       "A4_Score  -0.056508   0.140787  0.064918  0.193820 -0.013804   0.469945  \n",
       "A5_Score  -0.039688   0.009535  0.034378  0.090009  0.048976   0.537004  \n",
       "A6_Score  -0.083615   0.108745  0.078366  0.114048 -0.090688   0.592091  \n",
       "A7_Score   0.061900  -0.002004  0.030850 -0.008610  0.032594   0.351429  \n",
       "A8_Score   0.064127  -0.048702  0.012101  0.034845  0.051040   0.237161  \n",
       "A9_Score   0.006940   0.081052  0.057717  0.167644 -0.058046   0.635576  \n",
       "A10_Score -0.055246   0.059843  0.052201  0.117969  0.027427   0.385917  \n",
       "age       -0.051266   0.083560  0.065387  0.095511 -0.028200   0.060054  \n",
       "result    -0.042231   0.124213  0.094842  0.192033 -0.000760   0.821445  \n",
       "gender     1.000000  -0.091333 -0.018842 -0.088477 -0.065708  -0.080378  \n",
       "ethnicity -0.091333   1.000000  0.074951  0.117392  0.093633   0.144476  \n",
       "jundice   -0.018842   0.074951  1.000000  0.157793 -0.098007   0.102152  \n",
       "austim    -0.088477   0.117392  0.157793  1.000000 -0.119433   0.177415  \n",
       "relation  -0.065708   0.093633 -0.098007 -0.119433  1.000000   0.013165  \n",
       "Class/ASD -0.080378   0.144476  0.102152  0.177415  0.013165   1.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,0:17]\n",
    "y = data.iloc[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>result</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "0           1         1         1         1         0         0         1   \n",
       "1           1         1         0         1         0         0         0   \n",
       "2           1         1         0         1         1         0         1   \n",
       "3           1         1         0         1         0         0         1   \n",
       "4           1         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "699         0         1         0         1         1         0         1   \n",
       "700         1         0         0         0         0         0         0   \n",
       "701         1         0         1         1         1         0         1   \n",
       "702         1         0         0         1         1         0         1   \n",
       "703         1         0         1         1         1         0         1   \n",
       "\n",
       "     A8_Score  A9_Score  A10_Score  age  result  gender  ethnicity  jundice  \\\n",
       "0           1         0          0   26       6       0          9        0   \n",
       "1           1         0          1   24       5       1          3        0   \n",
       "2           1         1          1   27       8       1          3        1   \n",
       "3           1         0          1   35       6       0          9        0   \n",
       "4           1         0          0   40       2       0          9        0   \n",
       "..        ...       ...        ...  ...     ...     ...        ...      ...   \n",
       "699         1         1          1   25       7       0          9        0   \n",
       "700         1         0          1   34       3       1          2        0   \n",
       "701         1         0          1   24       7       0          9        0   \n",
       "702         0         1          1   35       6       1          7        0   \n",
       "703         1         1          1   26       8       0          9        0   \n",
       "\n",
       "     austim  relation  \n",
       "0         0         4  \n",
       "1         1         4  \n",
       "2         1         2  \n",
       "3         1         4  \n",
       "4         0         4  \n",
       "..      ...       ...  \n",
       "699       0         4  \n",
       "700       0         2  \n",
       "701       0         4  \n",
       "702       0         4  \n",
       "703       0         4  \n",
       "\n",
       "[704 rows x 17 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "699    1\n",
       "700    0\n",
       "701    1\n",
       "702    0\n",
       "703    1\n",
       "Name: Class/ASD, Length: 704, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bb2602adc8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    515\n",
       "1    189\n",
       "Name: Class/ASD, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class/ASD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bb2691a508>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['Class/ASD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(max_iter = 500)\n",
    "grid = {'C':[0.001,0.01,0.1],'penalty':['l1','l2'],'solver' : ['saga']}\n",
    "cv = KFold(n_splits = 5,random_state = None,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = x1,x,y1,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    515\n",
       "1    189\n",
       "Name: Class/ASD, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    728\n",
       "0    326\n",
       "Name: Class/ASD Traits , dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  Sex  \\\n",
       "0      0   0   0   0   0   0   1   1   0    1         2               3    0   \n",
       "1      1   1   0   0   0   1   1   0   0    0         3               4    1   \n",
       "2      1   0   0   0   0   0   1   1   0    1         3               4    1   \n",
       "3      1   1   1   1   1   1   1   1   1    1         2              10    1   \n",
       "4      1   1   0   1   1   1   1   1   1    1         1               9    0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...       ...             ...  ...   \n",
       "1049   0   0   0   0   0   0   0   0   0    1         2               1    0   \n",
       "1050   0   0   1   1   1   0   1   0   1    0         1               5    1   \n",
       "1051   1   0   1   1   1   1   1   1   1    1         1               9    1   \n",
       "1052   1   0   0   0   0   0   0   1   0    1         1               3    1   \n",
       "1053   1   1   0   0   1   1   0   1   1    0         2               6    1   \n",
       "\n",
       "      Ethnicity  Jaundice  Family_mem_with_ASD  Who completed the test  \n",
       "0             8         0                    1                       4  \n",
       "1             5         0                    1                       4  \n",
       "2             8         0                    1                       4  \n",
       "3             0         1                    1                       4  \n",
       "4             5         1                    0                       4  \n",
       "...         ...       ...                  ...                     ...  \n",
       "1049          5         1                    0                       4  \n",
       "1050          7         0                    1                       4  \n",
       "1051          8         0                    1                       4  \n",
       "1052          5         1                    0                       4  \n",
       "1053          6         0                    0                       4  \n",
       "\n",
       "[1054 rows x 17 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1049    0\n",
       "1050    1\n",
       "1051    1\n",
       "1052    0\n",
       "1053    1\n",
       "Name: Class/ASD Traits , Length: 1054, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=500, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(log,grid,cv = cv,n_jobs = -1,refit=True)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[231 284]\n",
      " [  0 189]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5965909090909091\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62       515\n",
      "           1       0.40      1.00      0.57       189\n",
      "\n",
      "    accuracy                           0.60       704\n",
      "   macro avg       0.70      0.72      0.60       704\n",
      "weighted avg       0.84      0.60      0.61       704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=500,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=None,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=6, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1],\n",
       "                                        'penalty': ['l1', 'l2'],\n",
       "                                        'solver': ['saga']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_clf = RandomizedSearchCV(log,grid,cv = cv,n_jobs = -1,refit=True,n_iter=6)\n",
    "r_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r_pred = r_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-45a75af93245>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'r_pred' is not defined"
     ]
    }
   ],
   "source": [
    "r_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62       515\n",
      "           1       0.40      1.00      0.57       189\n",
      "\n",
      "    accuracy                           0.60       704\n",
      "   macro avg       0.70      0.72      0.60       704\n",
      "weighted avg       0.84      0.60      0.61       704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1000, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC(kernel = 'rbf',gamma = 1000)\n",
    "clf_svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=rbf, score=0.735, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=2, gamma=1, kernel=rbf, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=rbf, score=0.711, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=2, gamma=1, kernel=rbf, score=0.705, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=rbf, score=0.981, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=rbf, score=0.990, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=rbf, score=0.991, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=rbf, score=0.995, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=rbf, score=0.825, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=rbf, score=0.801, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=rbf, score=0.744, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=rbf, score=0.815, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=rbf, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=poly, score=0.692, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=poly, score=0.711, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=2, gamma=0.001, kernel=poly, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=2, gamma=100, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=rbf, score=0.711, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=2, gamma=100, kernel=rbf, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=2, gamma=100, kernel=rbf, score=0.705, total=   0.1s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=3, gamma=1, kernel=rbf, score=0.735, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=rbf, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=rbf, score=0.711, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=3, gamma=1, kernel=rbf, score=0.705, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.981, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.990, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.995, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=poly, score=0.972, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.01, kernel=poly, score=0.971, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=rbf, score=0.825, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=rbf, score=0.801, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=rbf, score=0.744, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=rbf, score=0.815, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=rbf, score=0.833, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=poly, score=0.692, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=poly, score=0.711, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=3, gamma=0.001, kernel=poly, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=3, gamma=100, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=rbf, score=0.711, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=3, gamma=100, kernel=rbf, score=0.673, total=   0.2s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=rbf, score=0.701, total=   0.2s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=3, gamma=100, kernel=rbf, score=0.705, total=   0.1s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=4, gamma=1, kernel=rbf, score=0.735, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=rbf, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=rbf, score=0.711, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=4, gamma=1, kernel=rbf, score=0.705, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=0.1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=rbf, score=0.981, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=rbf, score=0.990, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=rbf, score=0.995, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=poly, score=0.948, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=poly, score=0.995, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=poly, score=0.981, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=poly, score=0.976, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.01, kernel=poly, score=0.962, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=rbf, score=0.825, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=rbf, score=0.801, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=rbf, score=0.744, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=rbf, score=0.815, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=rbf, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=poly, score=0.692, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=poly, score=0.711, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=0.1, degree=4, gamma=0.001, kernel=poly, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=4, gamma=100, kernel=rbf, score=0.701, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=rbf, score=0.711, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=4, gamma=100, kernel=rbf, score=0.673, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=rbf, score=0.701, total=   0.2s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, degree=4, gamma=100, kernel=rbf, score=0.705, total=   0.1s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=0.1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=2, gamma=1, kernel=rbf, score=0.867, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=rbf ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=1, degree=2, gamma=1, kernel=rbf, score=0.896, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=2, gamma=1, kernel=rbf, score=0.858, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=2, gamma=1, kernel=rbf, score=0.867, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=2, gamma=1, kernel=rbf, score=0.895, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=rbf, score=0.995, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=poly, score=0.716, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=poly, score=0.716, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=2, gamma=0.001, kernel=poly, score=0.695, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=2, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=rbf, score=0.730, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=poly ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.867, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.896, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.858, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.867, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.895, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=3, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=1, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=0.995, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.01, kernel=poly, score=0.986, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=poly, score=0.692, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=poly, score=0.711, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=3, gamma=0.001, kernel=poly, score=0.690, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=rbf, score=0.796, total=   0.2s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=3, gamma=100, kernel=rbf, score=0.730, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=3, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.867, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.896, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.858, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.867, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
      "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.895, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=poly .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=4, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=1, kernel=poly .............................\n",
      "[CV] . C=1, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=0.995, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.1, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=poly, score=0.976, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.01, kernel=poly ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.01, kernel=poly, score=0.971, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=rbf, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=rbf ..........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=poly, score=0.692, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=poly, score=0.711, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=0.001, kernel=poly .........................\n",
      "[CV]  C=1, degree=4, gamma=0.001, kernel=poly, score=0.690, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=rbf, score=0.796, total=   0.2s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=4, gamma=100, kernel=rbf, score=0.730, total=   0.2s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=rbf ............................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, degree=4, gamma=100, kernel=rbf, score=0.771, total=   0.2s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1, degree=4, gamma=100, kernel=poly ...........................\n",
      "[CV]  C=1, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=rbf .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=10, degree=2, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=2, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=2, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=2, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=rbf .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=10, degree=2, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly .........................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.1s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=rbf, score=0.796, total=   0.2s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=rbf, score=0.730, total=   0.2s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=rbf ..........................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=2, gamma=100, kernel=rbf, score=0.771, total=   0.2s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=3, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=poly .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=poly, score=0.739, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=poly, score=0.739, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=poly, score=0.668, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=poly, score=0.758, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=3, gamma=0.001, kernel=poly, score=0.771, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=3, gamma=100, kernel=rbf, score=0.730, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=3, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
      "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=4, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=1, kernel=poly ............................\n",
      "[CV]  C=10, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.1, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=10, degree=4, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.01, kernel=poly .........................\n",
      "[CV]  C=10, degree=4, gamma=0.01, kernel=poly, score=0.995, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=rbf .........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=poly, score=0.692, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=poly, score=0.711, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=poly, score=0.664, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=poly, score=0.697, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=0.001, kernel=poly ........................\n",
      "[CV]  C=10, degree=4, gamma=0.001, kernel=poly, score=0.690, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=4, gamma=100, kernel=rbf, score=0.730, total=   0.2s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=rbf ...........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, degree=4, gamma=100, kernel=rbf, score=0.771, total=   0.2s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=10, degree=4, gamma=100, kernel=poly ..........................\n",
      "[CV]  C=10, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=2, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=2, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=rbf ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=2, gamma=100, kernel=rbf, score=0.730, total=   0.2s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=2, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=2, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=poly ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=poly, score=0.972, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=poly .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=0.001, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=3, gamma=0.001, kernel=poly, score=0.971, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=100, kernel=rbf, score=0.730, total=   0.2s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=3, gamma=100, kernel=rbf, score=0.771, total=   0.2s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=3, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=1, kernel=poly ...........................\n",
      "[CV]  C=100, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.1, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.01, kernel=poly ........................\n",
      "[CV]  C=100, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=rbf ........................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=poly, score=0.749, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=poly, score=0.777, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=poly, score=0.673, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=poly .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=0.001, kernel=poly, score=0.758, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=0.001, kernel=poly .......................\n",
      "[CV]  C=100, degree=4, gamma=0.001, kernel=poly, score=0.790, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=rbf, score=0.730, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=rbf ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=rbf ..........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=poly .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=100, degree=4, gamma=100, kernel=poly .........................\n",
      "[CV]  C=100, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=2, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=poly ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=2, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=poly ......................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=rbf .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=2, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=rbf, score=0.796, total=   0.2s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=2, gamma=100, kernel=rbf, score=0.730, total=   0.2s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=rbf, score=0.763, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=poly ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=2, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=2, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=3, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=3, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=3, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=poly .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=rbf .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=3, gamma=0.001, kernel=poly, score=0.986, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=rbf, score=0.796, total=   0.2s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=rbf, score=0.730, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=rbf, score=0.763, total=   0.2s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=rbf, score=0.771, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=3, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=3, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=rbf ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=4, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=rbf, score=0.882, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=rbf, score=0.891, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=rbf ...........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=rbf, score=0.905, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=poly .........................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=1, kernel=poly ..........................\n",
      "[CV]  C=1000, degree=4, gamma=1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.1, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.1, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=rbf ........................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.01, kernel=poly .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.01, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=rbf .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=rbf .......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=poly, score=0.948, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=poly, score=0.995, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=poly, score=0.981, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=poly, score=0.976, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=0.001, kernel=poly ......................\n",
      "[CV]  C=1000, degree=4, gamma=0.001, kernel=poly, score=0.962, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=rbf, score=0.796, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=rbf .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, degree=4, gamma=100, kernel=rbf, score=0.730, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=rbf, score=0.763, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=rbf .........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=poly, score=0.991, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n",
      "[CV] C=1000, degree=4, gamma=100, kernel=poly ........................\n",
      "[CV]  C=1000, degree=4, gamma=100, kernel=poly, score=1.000, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 750 out of 750 | elapsed:   33.4s finished\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=700).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=300,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=700,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000], 'degree': [2, 3, 4],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 100],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "'gamma': [1, 0.1, 0.01, 0.001, 100],\n",
    "'degree':[2,3,4],\n",
    "'kernel': ['rbf','poly']} \n",
    "cv = KFold(n_splits = 5,random_state = None,shuffle = True)\n",
    "grid = GridSearchCV(SVC(cache_size = 300,max_iter = 700,), param_grid, cv = cv,refit = True, verbose = 3) \n",
    "\n",
    "grid.fit(x_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pred = grid.predict(x_test)\n",
    "grid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84       515\n",
      "           1       0.57      0.99      0.73       189\n",
      "\n",
      "    accuracy                           0.80       704\n",
      "   macro avg       0.79      0.86      0.79       704\n",
      "weighted avg       0.88      0.80      0.81       704\n",
      "\n",
      "[[376 139]\n",
      " [  1 188]]\n",
      "0.8011363636363636\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_pred))\n",
    "print(confusion_matrix(y_test,grid_pred))\n",
    "print(accuracy_score(y_test,grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "d_clf = DecisionTreeClassifier()\n",
    "d_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pred = d_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62       231\n",
      "           1       1.00      0.40      0.57       473\n",
      "\n",
      "    accuracy                           0.60       704\n",
      "   macro avg       0.72      0.70      0.60       704\n",
      "weighted avg       0.82      0.60      0.59       704\n",
      "\n",
      "0.5965909090909091\n",
      "[[231   0]\n",
      " [284 189]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(d_pred,y_test))\n",
    "print(accuracy_score(d_pred,y_test))\n",
    "print(confusion_matrix(d_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clf = RandomForestClassifier().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pred = r_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62       231\n",
      "           1       1.00      0.40      0.57       473\n",
      "\n",
      "    accuracy                           0.60       704\n",
      "   macro avg       0.72      0.70      0.60       704\n",
      "weighted avg       0.82      0.60      0.59       704\n",
      "\n",
      "0.5965909090909091\n",
      "[[231   0]\n",
      " [284 189]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(r_pred,y_test))\n",
    "print(accuracy_score(r_pred,y_test))\n",
    "print(confusion_matrix(r_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    704.000000\n",
       "mean      29.673295\n",
       "std       16.490476\n",
       "min       17.000000\n",
       "25%       21.000000\n",
       "50%       27.000000\n",
       "75%       35.000000\n",
       "max      383.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      26\n",
       "1      24\n",
       "2      27\n",
       "3      35\n",
       "4      40\n",
       "       ..\n",
       "699    25\n",
       "700    34\n",
       "701    24\n",
       "702    35\n",
       "703    26\n",
       "Name: age, Length: 704, dtype: int32"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.982276\ttraining's binary_error: 0.103416\ttraining's l1: 0.328068\ttraining's rmse: 0.356034\ttraining's l2: 0.12676\ttraining's mape: 0.328068\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[2]\ttraining's auc: 0.994754\ttraining's binary_error: 0.0616698\ttraining's l1: 0.257379\ttraining's rmse: 0.285172\ttraining's l2: 0.081323\ttraining's mape: 0.257379\n",
      "[3]\ttraining's auc: 0.999996\ttraining's binary_error: 0.0056926\ttraining's l1: 0.186447\ttraining's rmse: 0.206255\ttraining's l2: 0.0425412\ttraining's mape: 0.186447\n",
      "[4]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.136328\ttraining's rmse: 0.150894\ttraining's l2: 0.0227689\ttraining's mape: 0.136328\n",
      "[5]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.100131\ttraining's rmse: 0.110922\ttraining's l2: 0.0123038\ttraining's mape: 0.100131\n",
      "[6]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.079649\ttraining's rmse: 0.0910244\ttraining's l2: 0.00828544\ttraining's mape: 0.079649\n",
      "[7]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.0587187\ttraining's rmse: 0.0671725\ttraining's l2: 0.00451215\ttraining's mape: 0.0587187\n",
      "[8]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.0433498\ttraining's rmse: 0.0496367\ttraining's l2: 0.0024638\ttraining's mape: 0.0433498\n",
      "[9]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.0320345\ttraining's rmse: 0.0367108\ttraining's l2: 0.00134769\ttraining's mape: 0.0320345\n",
      "[10]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.0236889\ttraining's rmse: 0.0271607\ttraining's l2: 0.000737703\ttraining's mape: 0.0236889\n",
      "[11]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.017526\ttraining's rmse: 0.0201036\ttraining's l2: 0.000404154\ttraining's mape: 0.017526\n",
      "[12]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.012971\ttraining's rmse: 0.0148831\ttraining's l2: 0.000221508\ttraining's mape: 0.012971\n",
      "[13]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00960234\ttraining's rmse: 0.0110204\ttraining's l2: 0.00012145\ttraining's mape: 0.00960234\n",
      "[14]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00710986\ttraining's rmse: 0.00816128\ttraining's l2: 6.66064e-05\ttraining's mape: 0.00710986\n",
      "[15]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00581248\ttraining's rmse: 0.00698986\ttraining's l2: 4.88581e-05\ttraining's mape: 0.00581248\n",
      "[16]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.0043045\ttraining's rmse: 0.00517732\ttraining's l2: 2.68046e-05\ttraining's mape: 0.0043045\n",
      "[17]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00318803\ttraining's rmse: 0.00383491\ttraining's l2: 1.47065e-05\ttraining's mape: 0.00318803\n",
      "[18]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00236131\ttraining's rmse: 0.00284071\ttraining's l2: 8.06963e-06\ttraining's mape: 0.00236131\n",
      "[19]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00174905\ttraining's rmse: 0.00210428\ttraining's l2: 4.428e-06\ttraining's mape: 0.00174905\n",
      "[20]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.0012956\ttraining's rmse: 0.00155879\ttraining's l2: 2.42984e-06\ttraining's mape: 0.0012956\n",
      "[21]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000959728\ttraining's rmse: 0.00115474\ttraining's l2: 1.33343e-06\ttraining's mape: 0.000959728\n",
      "[22]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000710944\ttraining's rmse: 0.000855427\ttraining's l2: 7.31756e-07\ttraining's mape: 0.000710944\n",
      "[23]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.00058973\ttraining's rmse: 0.000751881\ttraining's l2: 5.65325e-07\ttraining's mape: 0.00058973\n",
      "[24]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000436865\ttraining's rmse: 0.000556999\ttraining's l2: 3.10248e-07\ttraining's mape: 0.000436865\n",
      "[25]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000323628\ttraining's rmse: 0.00041263\ttraining's l2: 1.70264e-07\ttraining's mape: 0.000323628\n",
      "[26]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000239745\ttraining's rmse: 0.000305682\ttraining's l2: 9.34418e-08\ttraining's mape: 0.000239745\n",
      "[27]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000197934\ttraining's rmse: 0.000262414\ttraining's l2: 6.88609e-08\ttraining's mape: 0.000197934\n",
      "[28]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000146631\ttraining's rmse: 0.000194399\ttraining's l2: 3.77911e-08\ttraining's mape: 0.000146631\n",
      "[29]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.000108626\ttraining's rmse: 0.000144014\ttraining's l2: 2.074e-08\ttraining's mape: 0.000108626\n",
      "[30]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 8.04712e-05\ttraining's rmse: 0.000106688\ttraining's l2: 1.13823e-08\ttraining's mape: 8.04712e-05\n",
      "[31]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 5.96142e-05\ttraining's rmse: 7.90361e-05\ttraining's l2: 6.24671e-09\ttraining's mape: 5.96142e-05\n",
      "[32]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 4.41631e-05\ttraining's rmse: 5.85513e-05\ttraining's l2: 3.42825e-09\ttraining's mape: 4.41631e-05\n",
      "[33]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 3.75093e-05\ttraining's rmse: 5.24809e-05\ttraining's l2: 2.75424e-09\ttraining's mape: 3.75093e-05\n",
      "[34]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 2.77875e-05\ttraining's rmse: 3.88788e-05\ttraining's l2: 1.51156e-09\ttraining's mape: 2.77875e-05\n",
      "[35]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 2.05854e-05\ttraining's rmse: 2.88021e-05\ttraining's l2: 8.2956e-10\ttraining's mape: 2.05854e-05\n",
      "[36]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.525e-05\ttraining's rmse: 2.13371e-05\ttraining's l2: 4.55272e-10\ttraining's mape: 1.525e-05\n",
      "[37]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.12975e-05\ttraining's rmse: 1.58069e-05\ttraining's l2: 2.49859e-10\ttraining's mape: 1.12975e-05\n",
      "[38]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 8.36937e-06\ttraining's rmse: 1.17101e-05\ttraining's l2: 1.37125e-10\ttraining's mape: 8.36937e-06\n",
      "[39]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 6.20018e-06\ttraining's rmse: 8.67502e-06\ttraining's l2: 7.5256e-11\ttraining's mape: 6.20018e-06\n",
      "[40]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 4.5932e-06\ttraining's rmse: 6.42662e-06\ttraining's l2: 4.13014e-11\ttraining's mape: 4.5932e-06\n",
      "[41]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 3.40273e-06\ttraining's rmse: 4.76095e-06\ttraining's l2: 2.26667e-11\ttraining's mape: 3.40273e-06\n",
      "[42]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 2.5208e-06\ttraining's rmse: 3.527e-06\ttraining's l2: 1.24398e-11\ttraining's mape: 2.5208e-06\n",
      "[43]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[44]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[45]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[46]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[47]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[48]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[49]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[50]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[51]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[52]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[53]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[54]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[55]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[56]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[57]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[58]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[59]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[60]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[61]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[62]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[63]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[64]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[65]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[66]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[67]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[68]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[69]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[70]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[71]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[72]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[73]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[74]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[75]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[76]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[77]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[78]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[79]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[80]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[81]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[82]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[83]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[84]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[85]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[87]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[88]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[89]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[90]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[91]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[92]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[93]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[94]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[95]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[96]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[97]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[98]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[99]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[100]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[101]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[102]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[103]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[104]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[105]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[106]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[107]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[108]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[109]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[110]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[111]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[112]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[113]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[114]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[115]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[116]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[117]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[118]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[119]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[120]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[121]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[122]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[123]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[124]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[125]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[126]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[127]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[128]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[129]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[130]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[131]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[132]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[133]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[134]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[135]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[136]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[137]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[138]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[139]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[140]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[141]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[142]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[143]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[144]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[145]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[146]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[147]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[148]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[149]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[150]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[151]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[152]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[153]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[154]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[155]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[156]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[157]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[158]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[159]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[160]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[161]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[162]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[164]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[165]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[166]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[167]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[168]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[169]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[170]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[171]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[172]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[173]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[174]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[175]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[176]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[177]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[178]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[179]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[180]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[181]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[182]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[183]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[184]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[185]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[186]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[187]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[188]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[189]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[190]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[191]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[192]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[193]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[194]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[195]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[196]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[197]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[198]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[199]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "[200]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 1.86746e-06\ttraining's rmse: 2.61287e-06\ttraining's l2: 6.82709e-12\ttraining's mape: 1.86746e-06\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4]\ttraining's auc: 1\ttraining's binary_error: 0\ttraining's l1: 0.136328\ttraining's rmse: 0.150894\ttraining's l2: 0.0227689\ttraining's mape: 0.136328\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric':'binary_logloss',\n",
    "    'metric': {'l2', 'auc','l1','binary_error','rmse','mape'},\n",
    "    'num_leaves': 256,\n",
    "    'learning_rate': 0.3,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbose': None,\n",
    "    'max_bin':255,\n",
    "    'num_threads':7,\n",
    "    'num_iterations':200,\n",
    "    'max_depth':8,\n",
    "    'min_data_in_leaf':10,\n",
    "    'gpu_use_dp':'True',\n",
    "    'alpha':0.5}\n",
    "lgb_train = lgb.Dataset(x1, y1)\n",
    "lgb_eval = lgb.Dataset(x, y)\n",
    "model = lgb.train(lgb_params,lgb_train,num_boost_round=200,valid_sets=lgb_train,early_stopping_rounds=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88186515, 0.86182038, 0.91091645, 0.86643334, 0.27819942,\n",
       "       0.91091645, 0.31636858, 0.89633361, 0.7796802 , 0.91241244,\n",
       "       0.9109266 , 0.83560586, 0.91147961, 0.81039647, 0.81039647,\n",
       "       0.85747089, 0.89747311, 0.2262183 , 0.20547956, 0.2376016 ,\n",
       "       0.15162629, 0.17394548, 0.85035297, 0.19729016, 0.85916066,\n",
       "       0.33996346, 0.17512758, 0.17809196, 0.18107613, 0.89390632,\n",
       "       0.17230849, 0.91189587, 0.88043451, 0.9109266 , 0.9109266 ,\n",
       "       0.16970291, 0.84077894, 0.91147961, 0.9109266 , 0.84914647,\n",
       "       0.91388696, 0.22953383, 0.24379023, 0.65777142, 0.90324592,\n",
       "       0.9114146 , 0.72094998, 0.92457803, 0.15485584, 0.91467223,\n",
       "       0.25592943, 0.9109266 , 0.16970291, 0.9133517 , 0.9109266 ,\n",
       "       0.91464388, 0.91148362, 0.91148362, 0.38322603, 0.85916066,\n",
       "       0.91189587, 0.87321647, 0.17230849, 0.82931666, 0.91110835,\n",
       "       0.26166713, 0.31636858, 0.83748319, 0.84594953, 0.25327538,\n",
       "       0.87043768, 0.14840188, 0.88226579, 0.89837437, 0.8764103 ,\n",
       "       0.91287848, 0.30785419, 0.9109266 , 0.76461187, 0.16133588,\n",
       "       0.87932631, 0.37726314, 0.9109266 , 0.74935793, 0.16133588,\n",
       "       0.30213493, 0.9109266 , 0.16970291, 0.71021238, 0.91148362,\n",
       "       0.69546735, 0.75569155, 0.8737165 , 0.91137668, 0.86602169,\n",
       "       0.87678255, 0.84944189, 0.91340138, 0.46932909, 0.3202096 ,\n",
       "       0.31828473, 0.27819942, 0.23035625, 0.90999492, 0.89155275,\n",
       "       0.17394548, 0.91430623, 0.90336845, 0.90506963, 0.28827248,\n",
       "       0.9109266 , 0.83109698, 0.28137971, 0.85235638, 0.91110835,\n",
       "       0.9114146 , 0.90324592, 0.9171339 , 0.91148362, 0.9114146 ,\n",
       "       0.91148362, 0.9109266 , 0.17428804, 0.91404071, 0.9109266 ,\n",
       "       0.91272609, 0.17232239, 0.90665519, 0.87932631, 0.77520653,\n",
       "       0.46932909, 0.30213493, 0.46932909, 0.82469682, 0.90398607,\n",
       "       0.78959792, 0.91018952, 0.23726569, 0.38534243, 0.19722123,\n",
       "       0.76246418, 0.27819942, 0.26166713, 0.86267863, 0.17635056,\n",
       "       0.9109266 , 0.9109266 , 0.9109266 , 0.9116272 , 0.90038593,\n",
       "       0.24535325, 0.91388696, 0.73646943, 0.91809155, 0.84594953,\n",
       "       0.27057841, 0.87321193, 0.7656177 , 0.7169023 , 0.30785419,\n",
       "       0.17394548, 0.31636858, 0.17635056, 0.45649398, 0.85593837,\n",
       "       0.842451  , 0.78151055, 0.84944189, 0.87879023, 0.86506731,\n",
       "       0.88226579, 0.88043451, 0.74492915, 0.27819942, 0.23277279,\n",
       "       0.8854122 , 0.91148362, 0.87879023, 0.81418751, 0.86337478,\n",
       "       0.84594953, 0.73661925, 0.87263539, 0.74492915, 0.91825429,\n",
       "       0.91133237, 0.81131176, 0.81039647, 0.91148362, 0.91706664,\n",
       "       0.91148362, 0.86182038, 0.30213493, 0.27819942, 0.26479316,\n",
       "       0.9109266 , 0.9109266 , 0.9109266 , 0.89323529, 0.60080247,\n",
       "       0.90038593, 0.82931666, 0.81580146, 0.9109266 , 0.13567282,\n",
       "       0.9109266 , 0.9109266 , 0.82480447, 0.88312914, 0.9109266 ,\n",
       "       0.9109266 , 0.83109698, 0.91467223, 0.69546735, 0.62231981,\n",
       "       0.90357663, 0.73070534, 0.87678255, 0.90336845, 0.17594323,\n",
       "       0.46932909, 0.16970291, 0.85474156, 0.84914647, 0.9109266 ,\n",
       "       0.82299457, 0.91404071, 0.17538907, 0.85869997, 0.91404071,\n",
       "       0.31896269, 0.18700684, 0.20269904, 0.85235638, 0.16996503,\n",
       "       0.27819942, 0.91518529, 0.22025889, 0.40104866, 0.27819942,\n",
       "       0.91127404, 0.91809155, 0.82064595, 0.90331171, 0.85682792,\n",
       "       0.81131176, 0.90946622, 0.83109698, 0.22726463, 0.9109266 ,\n",
       "       0.30785419, 0.78831699, 0.1560599 , 0.27123252, 0.37492878,\n",
       "       0.83330981, 0.81754511, 0.70338204, 0.9076048 , 0.89747311,\n",
       "       0.27057841, 0.8108122 , 0.30785419, 0.17394548, 0.77520653,\n",
       "       0.9126419 , 0.22850776, 0.3052134 , 0.85474156, 0.90839899,\n",
       "       0.91148362, 0.88658254, 0.9109266 , 0.16982913, 0.87678255,\n",
       "       0.89697074, 0.28570148, 0.16133588, 0.9109266 , 0.20500842,\n",
       "       0.17428804, 0.86602169, 0.90351827, 0.9109266 , 0.23087334,\n",
       "       0.91242393, 0.17230849, 0.85474156, 0.17232239, 0.89354509,\n",
       "       0.89354509, 0.81456595, 0.79943982, 0.84594953, 0.17394548,\n",
       "       0.91148362, 0.91148362, 0.91532588, 0.8311057 , 0.9109266 ,\n",
       "       0.23277279, 0.9109266 , 0.90385014, 0.286844  , 0.87879023,\n",
       "       0.68130237, 0.90096112, 0.9109266 , 0.91148362, 0.9046515 ,\n",
       "       0.15601913, 0.74874026, 0.90358209, 0.9114146 , 0.85474156,\n",
       "       0.46932909, 0.8174022 , 0.83028768, 0.81418751, 0.17394548,\n",
       "       0.16133588, 0.82299457, 0.9116272 , 0.78017238, 0.20944328,\n",
       "       0.81418751, 0.81418751, 0.24535325, 0.87678255, 0.35881702,\n",
       "       0.87678255, 0.9109266 , 0.9109266 , 0.90325974, 0.83534306,\n",
       "       0.88312914, 0.86965822, 0.22857466, 0.79683752, 0.35368811,\n",
       "       0.83960866, 0.85474156, 0.13567282, 0.18700684, 0.86607707,\n",
       "       0.16970291, 0.90624169, 0.17635056, 0.84914647, 0.85916066,\n",
       "       0.90198763, 0.88325299, 0.31636858, 0.37492878, 0.1560599 ,\n",
       "       0.24535325, 0.83086586, 0.27819942, 0.87248333, 0.16962685,\n",
       "       0.82064595, 0.29649441, 0.31397578, 0.20557159, 0.82299457,\n",
       "       0.8257835 , 0.81418751, 0.88829514, 0.81418751, 0.286844  ,\n",
       "       0.20149525, 0.85747089, 0.20446594, 0.30213493, 0.91127404,\n",
       "       0.37411187, 0.27819942, 0.87179096, 0.27819942, 0.29341259,\n",
       "       0.25426658, 0.27819942, 0.90038593, 0.81039647, 0.46932909,\n",
       "       0.20149525, 0.17594323, 0.91777652, 0.83330981, 0.31636858,\n",
       "       0.38322603, 0.87879023, 0.88611641, 0.46932909, 0.90509854,\n",
       "       0.86607707, 0.67164538, 0.38010409, 0.2985061 , 0.16970291,\n",
       "       0.86695963, 0.29496303, 0.87248333, 0.87248333, 0.30036915,\n",
       "       0.30785419, 0.85678204, 0.91115378, 0.85474156, 0.16133588,\n",
       "       0.68130237, 0.28993148, 0.74874026, 0.74492915, 0.91388696,\n",
       "       0.15601913, 0.64954564, 0.87291594, 0.89530699, 0.84594953,\n",
       "       0.85593837, 0.15006345, 0.79501073, 0.1955606 , 0.88480253,\n",
       "       0.81039647, 0.91464388, 0.78831699, 0.2038011 , 0.90624169,\n",
       "       0.9109266 , 0.9109266 , 0.27467592, 0.9114146 , 0.19757898,\n",
       "       0.16104641, 0.62231981, 0.90472907, 0.87678255, 0.31636858,\n",
       "       0.92033143, 0.16608238, 0.9186917 , 0.84176888, 0.87133835,\n",
       "       0.29496303, 0.90096112, 0.27819942, 0.9109266 , 0.85916066,\n",
       "       0.45649398, 0.14840188, 0.86533956, 0.74492915, 0.48606728,\n",
       "       0.26671847, 0.78017238, 0.15006345, 0.91148362, 0.85747089,\n",
       "       0.19097906, 0.18107613, 0.91147961, 0.32785882, 0.91110835,\n",
       "       0.19757898, 0.84917728, 0.81072274, 0.91404071, 0.18195896,\n",
       "       0.35246183, 0.91388696, 0.74492915, 0.30213493, 0.91340138,\n",
       "       0.33340225, 0.17228086, 0.27819942, 0.82064595, 0.17635056,\n",
       "       0.84944189, 0.2262183 , 0.16241792, 0.88312914, 0.79784589,\n",
       "       0.40104866, 0.9109266 , 0.91148362, 0.89537861, 0.85916066,\n",
       "       0.8765054 , 0.17232239, 0.842451  , 0.9109266 , 0.88312914,\n",
       "       0.13567282, 0.30006666, 0.91404071, 0.91388696, 0.45649398,\n",
       "       0.87879023, 0.91148362, 0.86823333, 0.85474156, 0.90096112,\n",
       "       0.85408837, 0.82805902, 0.70338204, 0.9109266 , 0.19722123,\n",
       "       0.91112783, 0.9109266 , 0.69799723, 0.13567282, 0.90038593,\n",
       "       0.91148362, 0.88043451, 0.91091645, 0.4085151 , 0.24379023,\n",
       "       0.86602169, 0.84285811, 0.90038593, 0.86188053, 0.91532588,\n",
       "       0.81131176, 0.80618209, 0.31232259, 0.9109266 , 0.31636858,\n",
       "       0.22902343, 0.88325299, 0.65777142, 0.91094611, 0.85864719,\n",
       "       0.22142587, 0.22902343, 0.89228538, 0.79501073, 0.86188053,\n",
       "       0.91148362, 0.18097361, 0.91404071, 0.91404071, 0.9109266 ,\n",
       "       0.91189587, 0.69546735, 0.79943982, 0.88312914, 0.9109266 ,\n",
       "       0.16133588, 0.27982814, 0.17428804, 0.9126419 , 0.91148362,\n",
       "       0.86267863, 0.46932909, 0.78017238, 0.91110835, 0.86188053,\n",
       "       0.9109266 , 0.9109266 , 0.9110648 , 0.84410076, 0.89716651,\n",
       "       0.31636858, 0.80523636, 0.88325299, 0.91148362, 0.13567282,\n",
       "       0.68130237, 0.29496303, 0.23277279, 0.9109266 , 0.84944189,\n",
       "       0.84944189, 0.89368104, 0.90038593, 0.86602169, 0.45649398,\n",
       "       0.16966321, 0.73646943, 0.90398607, 0.91100917, 0.84176888,\n",
       "       0.87932631, 0.9109266 , 0.91148362, 0.9109266 , 0.14310108,\n",
       "       0.89837437, 0.91686601, 0.9109266 , 0.16970291, 0.77520653,\n",
       "       0.45649398, 0.87678255, 0.842451  , 0.3052134 , 0.78959792,\n",
       "       0.22850776, 0.26166713, 0.15601913, 0.27819942, 0.38534243,\n",
       "       0.87368705, 0.30785419, 0.18195896, 0.16970291, 0.78831699,\n",
       "       0.87693885, 0.84944189, 0.62231981, 0.16970291, 0.85916066,\n",
       "       0.87053462, 0.43670898, 0.80410942, 0.19722123, 0.83086586,\n",
       "       0.86823333, 0.91231997, 0.84944189, 0.91091645, 0.3052134 ,\n",
       "       0.85593837, 0.26166713, 0.30785419, 0.842451  , 0.91809155,\n",
       "       0.90940824, 0.16962685, 0.15456663, 0.78346259, 0.9122213 ,\n",
       "       0.89537861, 0.17232239, 0.9109266 , 0.85747089, 0.9032643 ,\n",
       "       0.87678255, 0.91091645, 0.24535325, 0.17428804, 0.85747089,\n",
       "       0.83215482, 0.60080247, 0.81147307, 0.74492915, 0.16279938,\n",
       "       0.16133588, 0.30562331, 0.17938256, 0.9109266 , 0.91091645,\n",
       "       0.90946622, 0.91809155, 0.90668801, 0.36006373, 0.91148362,\n",
       "       0.89378751, 0.91148362, 0.91147961, 0.81039647, 0.26387234,\n",
       "       0.9109266 , 0.17635056, 0.35345523, 0.81039647, 0.9109266 ,\n",
       "       0.91091645, 0.84176888, 0.9149518 , 0.9126419 , 0.90472907,\n",
       "       0.89633361, 0.84757355, 0.38534243, 0.86506731, 0.9109266 ,\n",
       "       0.9109266 , 0.9109266 , 0.45649398, 0.85235638, 0.75029476,\n",
       "       0.86602169, 0.83948789, 0.89368104, 0.9109266 , 0.89334044,\n",
       "       0.25440086, 0.78831699, 0.91272609, 0.83086586, 0.84285811,\n",
       "       0.79784589, 0.91148362, 0.73661925, 0.9109266 , 0.87100365,\n",
       "       0.30213493, 0.9149518 , 0.9170345 , 0.90096112])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgb=model.predict(x)\n",
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(y_pred_lgb)):\n",
    "    if y_pred_lgb[i]>=.5:\n",
    "        y_pred_lgb[i]=1\n",
    "    else:  \n",
    "        y_pred_lgb[i]=0\n",
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[231 284]\n",
      " [  0 189]] 0.5965909090909091\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y, y_pred_lgb)\n",
    "accuracy=accuracy_score(y,y_pred_lgb)\n",
    "print(cm,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Personal\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer = 'adam'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(1054,activation='relu',input_dim = 17))\n",
    "    model.add(keras.layers.Dense(50,activation = 'sigmoid'))\n",
    "    model.add(keras.layers.Dense(1,activation = 'relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 150, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 247, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 240, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 482, in dump\n    return Pickler.dump(self, obj)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 890, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 819, in save_list\n    self._batch_appends(obj)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 846, in _batch_appends\n    save(tmp[0])\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 774, in save_tuple\n    save(element)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 774, in save_tuple\n    save(element)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 556, in save_function\n    return self.save_function_tuple(obj)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 758, in save_function_tuple\n    save(state)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 890, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\Personal\\Anaconda3\\lib\\pickle.py\", line 524, in save\n    rv = reduce(self.proto)\nTypeError: can't pickle _LazyLoader objects\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-76d45226c397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best: %f using %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "scorers = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'accuracy_score': make_scorer(accuracy_score)\n",
    "        }\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,scoring = scorers, n_jobs=-1, cv=3,refit = False)\n",
    "grid_result = grid.fit(x, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
